{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing a toy example for demonstrating MAML. Regression to a sine wave. Tasks are waves with different amplitudes and phases. Model is first pre-trained on a sample of training tasks using higher-order gradients as described in MAML. During testing, it is fine-tuned on `k` examples from an evaluation task.\n",
    "\n",
    "This is benchmarked against pretraining a model on a sample of training tasks which is then finetuned on `k` examples from the evaluation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from higher import innerloop_ctx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import notebook_setup\n",
    "import ppo, utils, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks\n",
    "# sin waves with amplitude [0.1, 5] and phase [0, pi]\n",
    "def get_task(seed=None):\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    phase = rnd.rand(1) * np.pi\n",
    "    amplitude = 0.1 + rnd.rand(1) * 4.9\n",
    "    return amplitude, phase\n",
    "\n",
    "def get_samples(k, amplitude, phase, seed=None):\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    x = -5 + 10 * rnd.rand(k)\n",
    "    y = amplitude * np.sin(x + phase)\n",
    "    return torch.from_numpy(x).float().reshape(-1, 1), torch.from_numpy(y).float().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_tasks = 5\n",
    "training_tasks = list(range(n_training_tasks))  # random seeds for generating task parameters\n",
    "evaluation_tasks = [11]\n",
    "k = 10        # number of examples per task\n",
    "n_adapt = 10\n",
    "alpha = 0.01 # global learning rate\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    model = nn.Sequential(\n",
    "            nn.Linear(1, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, n=100, losses=[]):\n",
    "    \"\"\"Pre-training model using higher-order gradients on per-task samples from `training_tasks`\"\"\"\n",
    "    for _ in trange(n, leave=False):\n",
    "        opti = optim.Adam(model.parameters(), lr=alpha)\n",
    "        for i, task in enumerate(map(get_task, training_tasks)):\n",
    "            with innerloop_ctx(model, opti, copy_initial_weights=False) as (fmodel, diffopt):\n",
    "\n",
    "                xi, yi = get_samples(k, *task)\n",
    "                y_ = fmodel(xi)\n",
    "                l = loss(y_, yi)\n",
    "                diffopt.step(l)\n",
    "\n",
    "                xi, yi = get_samples(k, *task)\n",
    "                y_ = fmodel(xi)\n",
    "                l = loss(y_, yi)\n",
    "                l.backward()\n",
    "                if losses is not None:\n",
    "                    losses[i].append(l.item())\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "def benchmark_train(model, opt, n=100, losses=[]):\n",
    "    \"\"\"Pre-training model on aggregated samples from `training_tasks`\"\"\"\n",
    "    for _ in trange(n, leave=False):\n",
    "        for i, task in enumerate(map(get_task, training_tasks)):\n",
    "\n",
    "                xi, yi = get_samples(k, *task)\n",
    "                y_ = model(xi)\n",
    "                l = loss(y_, yi)\n",
    "                l.backward()\n",
    "                if losses is not None:\n",
    "                    losses[i].append(l.item())\n",
    "\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, seed=0, losses=None, predict=None):\n",
    "    \"\"\"Fine-tuning model on tasks contained in `evaluation_tasks`\"\"\"\n",
    "    opti = optim.Adam(model.parameters(), lr=alpha)\n",
    "    for i, task in enumerate(map(get_task, evaluation_tasks)):\n",
    "        with innerloop_ctx(model, opti, track_higher_grads=False) as (fmodel, diffopt):\n",
    "\n",
    "            xi, yi = get_samples(k, *task, seed=seed)\n",
    "            for _ in range(n_adapt):\n",
    "                y_ = fmodel(xi)\n",
    "                l = loss(y_, yi)\n",
    "                diffopt.step(l)\n",
    "\n",
    "            if losses is not None:\n",
    "                xi, yi = get_samples(k, *task, seed=seed + 1)\n",
    "                y_ = fmodel(xi)\n",
    "                l = loss(y_, yi)\n",
    "                losses[i].append(l.item())\n",
    "            \n",
    "            if predict is not None:\n",
    "                return fmodel(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = make_model()\n",
    "bench = make_model()\n",
    "bench.load_state_dict(model.state_dict())\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=alpha)\n",
    "optb = optim.Adam(bench.parameters(), lr=alpha)\n",
    "\n",
    "losses_train = [[] for _ in training_tasks]\n",
    "losses_bench_train = [[] for _ in training_tasks]\n",
    "losses_test = [[] for _ in evaluation_tasks]\n",
    "losses_bench_test = [[] for _ in evaluation_tasks]\n",
    "\n",
    "for epoch in trange(10, leave=False):\n",
    "    train(model, opt, 100, losses_train)\n",
    "    benchmark_train(bench, optb, 100, losses_bench_train)\n",
    "    test(model, losses=losses_test)\n",
    "    test(bench, losses=losses_bench_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss perfomance\n",
    "for t, tb in zip(losses_test, losses_bench_test):\n",
    "    plt.plot(t, label='Test')\n",
    "    plt.plot(tb, label='Bench')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting actual outputs\n",
    "x = torch.from_numpy(np.linspace(-5, 5, 50, False).reshape(-1, 1)).float()\n",
    "y_pre = model(x).data\n",
    "y_post = test(model, predict=x).data\n",
    "y_b_pre = bench(x).data\n",
    "y_b_post = test(bench, predict=x).data\n",
    "amp, ph = get_task(evaluation_tasks[-1])\n",
    "y = amp * np.sin(x.data.numpy() + ph)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x, y_pre, label='Test(Pre)', c='b', ls=':')\n",
    "plt.plot(x, y_post, label='Test(Post)', c='b')\n",
    "plt.plot(x, y_b_pre, label='Bench(Pre)', c='r', ls=':')\n",
    "plt.plot(x, y_b_post, label='Bench(Post)', c='r')\n",
    "plt.plot(x, y, label='True', c='g')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit2b6a5ffea75d4de087eb7d5fb87e4f6e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
