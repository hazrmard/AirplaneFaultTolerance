{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import notebook_setup\n",
    "\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import warnings\n",
    "import os\n",
    "# warnings.filterwarnings(\"error\", category=UserWarning)\n",
    "os.makedirs(os.path.expanduser('~/Data/tensorboard/'), exist_ok=True)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import gym\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "from pytorchbridge import TorchEstimator\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from ppo import PPO, Memory, ActorCriticDiscrete, returns\n",
    "from systems import LunarLanderEnv, random_lunarlander, plot_lunarlander\n",
    "from utils import (cache_function, cache_to_episodic_rewards,\n",
    "                   cache_to_episodes, copy_tensor, copy_mlp_regressor,\n",
    "                   sanitize_filename, get_gradients)\n",
    "from meta import (learn_env_model, meta_update, distance, prune_library,\n",
    "                  plot_adaption, rank_policies, maml_initialize)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 0\n",
    "NCPU = os.cpu_count() // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'LunarLander'\n",
    "env = LunarLanderEnv(seed=SEED)\n",
    "PhysicalEnv = LunarLanderEnv\n",
    "DataEnv = None\n",
    "nominal_config = dict(\n",
    "    MAIN_ENGINE_POWER=13.,\n",
    "    SIDE_ENGINE_POWER=0.6\n",
    ")\n",
    "env_fn = lambda seed=SEED: PhysicalEnv(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Episode length: 91.3\n"
     ]
    }
   ],
   "source": [
    "env = env_fn()\n",
    "i, n=0, 20\n",
    "for _ in trange(n, leave=False):\n",
    "    env.reset()\n",
    "    done=False\n",
    "    while not done:\n",
    "        _, _, done, _ = env.step(env.action_space.sample())\n",
    "        i += 1\n",
    "print('Average Episode length:', i / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrade(env, time: float, factor: np.ndarray, **nominal):\n",
    "    tanks = env.tanks\n",
    "    if not isinstance(factor, (list, tuple, np.ndarray)):\n",
    "        # If a single degradation factor given, assume it is\n",
    "        # identical for all tanks.\n",
    "        tfactor = np.ones(n_tanks) * tfactor\n",
    "    \n",
    "    for i in range(n_engines):\n",
    "        tanks.engines[i] = nominal['engines'][i] + \\\n",
    "                           nominal['engines'][i] * time / efactor[i]\n",
    "\n",
    "\n",
    "def random_degrade(env, random=np.random,\n",
    "                   tfactors=(10, 20), efactors=(10, 20),\n",
    "                   atmost_tanks=1, atmost_engines=1):\n",
    "    n_tanks = len(tanks.heights)\n",
    "    tanks = env.tanks\n",
    "    tfactor = np.ones(n_tanks) * np.inf\n",
    "    if atmost_tanks > 0:\n",
    "        tanks_affected = random.randint(1, atmost_tanks + 1)\n",
    "        idx_affected = random.choice(n_tanks, size=tanks_affected, replace=False)\n",
    "        tfactor[idx_affected] = random.randint(*tfactors, size=tanks_affected)\n",
    "        \n",
    "    efactor = np.ones(n_engines) * np.inf\n",
    "    if atmost_engines > 0:\n",
    "        engines_affected = random.randint(1, atmost_engines + 1)\n",
    "        idx_affected = random.choice(n_engines, size=engines_affected, replace=False)\n",
    "        efactor[idx_affected] = random.randint(*efactors, size=engines_affected)\n",
    "    \n",
    "    degrade(env, min([t if t != np.inf else 0 for t in tfactor]), tfactor, efactor, **nominal_config)\n",
    "    return tfactor, efactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env_fn()\n",
    "timesteps = 100000            # max timesteps in one episode\n",
    "\n",
    "ppo_params = dict(\n",
    "    state_dim = env.observation_space.shape[0],\n",
    "    action_dim = 4,\n",
    "    policy=ActorCriticDiscrete,\n",
    "    epochs = 3,                  # update policy for K epochs\n",
    "    lr = 0.001,                   # learning rate\n",
    "    n_latent_var = 64,           # number of variables in hidden layer\n",
    "    betas = (0.9, 0.999),\n",
    "    gamma = 0.99,                # discount factor\n",
    "    eps_clip = 0.2,              # clip parameter for PPO\n",
    "    update_interval = 500,      # update policy every n timesteps\n",
    "    seed = SEED\n",
    ")\n",
    "library_size = 4\n",
    "random_library = False\n",
    "random_fault = False\n",
    "data_model = False\n",
    "random = np.random.RandomState(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal agent trained without fault\n",
    "agent = PPO(env, **ppo_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = agent.learn(timesteps, track_higher_gradients=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.arange(len(r)), r)\n",
    "plt.title('Rewards on system under nominal conditions');\n",
    "# plt.ylim(bottom=0, top=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate library of policies\n",
    "library = []\n",
    "library_rewards = []\n",
    "library_envs = []\n",
    "library_grads = []\n",
    "\n",
    "if random_library:\n",
    "    library_envs = [random_degrade(env_fn(), random) for _ in range(library_size)]\n",
    "else:\n",
    "    env_params = [\n",
    "        # TODO\n",
    "        ]\n",
    "    for env_param in env_params:\n",
    "        env_ = env_fn()\n",
    "        env_.set_parameters(**env_param)\n",
    "        library_envs.append(env_)\n",
    "\n",
    "for env_ in tqdm(library_envs, leave=False):\n",
    "    if data_model:\n",
    "        est_ = copy_mlp_regressor(est)  # copy estimator hyperparameters etc.\n",
    "        x, y = generate_training_data(env_, episodes=50)  # random actions!\n",
    "        est_.fit(x, y)\n",
    "        # Train agent on data-driven model\n",
    "        env_ = DataEnv(env_, est_)\n",
    "    agent_ = PPO(env_, **ppo_params)\n",
    "    agent_.policy.load_state_dict(copy_tensor(agent.policy.state_dict()))\n",
    "    rewards = agent_.learn(timesteps, track_higher_gradients=True)\n",
    "    library.append(copy_tensor(agent_.policy.state_dict()))\n",
    "    library_rewards.append(rewards)\n",
    "    library_grads.append(get_gradients(agent_.meta_policy.parameters(), agent_.meta_policy.parameters(time=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot library rewards\n",
    "plt.figure(figsize=(6, 4))\n",
    "for i, rewards in enumerate(library_rewards):\n",
    "    plt.plot(rewards, label='Policy#{}'.format(i))\n",
    "plt.title('Episodic rewards on process with faults')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Reward')\n",
    "plt.legend()\n",
    "plt.grid(True, 'both')\n",
    "plt.tight_layout()\n",
    "\n",
    "pth = f'./bin/{env_name}/'\n",
    "os.makedirs(pth, exist_ok=True)\n",
    "plt.savefig(pth+env_name+'_library_rewards.png')\n",
    "with open(pth + env_name + '_library_rewards.pickle', 'wb') as f:\n",
    "    pickle.dump(dict(library_rewards=library_rewards), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faulty environment\n",
    "env_ = env_fn()\n",
    "if not random_fault:\n",
    "    env_.set_parameters(\n",
    "        MAIN_ENGINE_POWER=,\n",
    "        SIDE_ENGINE_POWER=\n",
    "    )\n",
    "else:\n",
    "    random_degrade(env_, random, **nominal_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Experiment functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def adapt(agent, est, memory, library, interactive_env=True,\n",
    "          n_inner=1, n_outer=1, alpha_inner=0.01, alpha_outer=0.1,\n",
    "          mode='fomaml', library_grads=None, rank=-1, **ppo_params):\n",
    "    env_ = agent.env\n",
    "    params = meta_update(agent.policy.state_dict(), env_, library, memory,\n",
    "                         n_inner, n_outer, alpha_inner, alpha_outer,\n",
    "                         interactive_env, mode, library_grads, rank, **ppo_params)\n",
    "    agent.policy.load_state_dict(params)\n",
    "    return agent\n",
    "\n",
    "def adapt_benchmark(agent, est, memory, library, interactive_env=True,\n",
    "          n_inner=1, n_outer=1, alpha_inner=0.01, alpha_outer=0.1,\n",
    "           mode=None, library_grads=None, rank=None, **ppo_params):\n",
    "    env_ = agent.env\n",
    "    agent.learn(ppo_params['update_interval'], ppo_params['update_interval'])\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def trial(env_, est, starting_policy, library=[], interactive_env=False, post_steps=10000,\n",
    "          n_inner=1, n_outer=1, alpha_inner=0.01, alpha_outer=0.1,\n",
    "          mode='fomaml', library_grads=None, rank=-1, benchmark=True, seed=SEED):\n",
    "    # local copy of ppo_params with seed overwritten with the trial seed\n",
    "    ppo_params['seed'] = seed\n",
    "    env_.seed(seed)\n",
    "    # Make copies of env, and agent trained on nominal system,\n",
    "    # and starting library of policies (if any)\n",
    "    library_ = [copy_tensor(p) for p in library]\n",
    "    agent_ = PPO(env_, **ppo_params)\n",
    "    agent_.policy.load_state_dict(copy_tensor(starting_policy))\n",
    "    # Fault occurs, buffer experience with environment\n",
    "    memory_ = Memory()\n",
    "    agent_.experience(memory_, 4*ppo_params['update_interval'], env_, agent_.policy)\n",
    "    # Use meta-learning to adapt to fault\n",
    "    agent_.env.reset()\n",
    "    adapt(agent_, est, memory_, library_, interactive_env,\n",
    "          n_inner, n_outer, alpha_inner, alpha_outer,\n",
    "          mode, library_grads, rank, **ppo_params)\n",
    "    if benchmark:\n",
    "        library_maml, gradients_maml = \\\n",
    "            maml_initialize(starting_policy, env_fn, library_size,\n",
    "                            n_inner, alpha_inner, **ppo_params)\n",
    "        agent_benchmark_maml = PPO(env_, **ppo_params)\n",
    "        agent_benchmark_maml.env.seed(seed)\n",
    "        agent_benchmark_maml.env.reset()\n",
    "        agent_benchmark_maml.policy.load_state_dict(copy_tensor(starting_policy))\n",
    "        adapt(agent_benchmark_maml, est, memory_, library_maml, True,\n",
    "              0, n_outer, alpha_inner, alpha_outer,\n",
    "              mode, gradients_maml, rank=-1, **ppo_params)\n",
    "        \n",
    "        agent_benchmark_vanilla = PPO(env_, **ppo_params)\n",
    "        agent_benchmark_vanilla.env.seed(seed)\n",
    "        agent_benchmark_vanilla.env.reset()\n",
    "        agent_benchmark_vanilla.policy.load_state_dict(copy_tensor(starting_policy))\n",
    "        adapt_benchmark(agent_benchmark_vanilla, est, memory_, library_, data_model,\n",
    "                        n_inner, n_outer, alpha_inner, alpha_outer,\n",
    "                        **ppo_params)\n",
    "        \n",
    "    # Continue learning\n",
    "    rewards = []\n",
    "    agents = [agent_, agent_benchmark_maml, agent_benchmark_vanilla] if benchmark else [agent_]\n",
    "    for a in tqdm(agents, desc='Post-fault training', leave=False):\n",
    "        rewards.append(a.learn(post_steps))\n",
    "    return rewards, agent_.policy.state_dict(), memory_\n",
    "\n",
    "\n",
    "\n",
    "def ntrials(n=NCPU, verbose=10, *trial_args, **trial_kwargs):\n",
    "\n",
    "    res = Parallel(n_jobs=min(n, NCPU), verbose=verbose)(\n",
    "        delayed(trial)(*trial_args, seed=SEED+i, **trial_kwargs) for i in range(n)\n",
    "    )\n",
    "    # res = [\n",
    "    #   [[[r..],[r..],[r..]], state_dict, memory]\n",
    "    # ]\n",
    "    n_rewards = len(res[0][0]) # our approach, maml, vanilla ppo\n",
    "    means, stds = [], []\n",
    "    for reward_idx in range(n_rewards):\n",
    "        maxlen = max([len(r[0][reward_idx]) for r in res])\n",
    "        rewards = np.empty((len(res), maxlen))\n",
    "        rewards.fill(np.nan)\n",
    "        for i, result in enumerate(res):\n",
    "            rewards[i, :len(result[0][reward_idx])] = result[0][reward_idx]\n",
    "        means.append(np.nanmean(rewards, axis=0))\n",
    "        stds.append(np.nanstd(rewards, axis=0))\n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid = ParameterGrid(dict(\n",
    "    alpha_inner = [1e-3, 1e-2, 1e-1],\n",
    "    alpha_outer = [1e-3, 1e-2, 1e-1],\n",
    "    n_inner = [0, 3],\n",
    "    n_outer = [1, 3],\n",
    "    data_model = [False],\n",
    "    post_steps = [30000],\n",
    "    library = [library],\n",
    "    library_grads = [library_grads],\n",
    "    rank = [-1, 1, 2],\n",
    "    mode = ['maml', 'fomaml', 'reptile']\n",
    "))\n",
    "\n",
    "pth = f'./bin/{env_name}/hyperparameters/'\n",
    "os.makedirs(pth, exist_ok=True)\n",
    "\n",
    "env_ = env_fn()\n",
    "env_.set_parameters(\n",
    "    masscart=1.5,\n",
    "    masspole=0.1,\n",
    "    length=0.5,\n",
    "    force_mag=-10,\n",
    ")\n",
    "\n",
    "hyp_r, hyp_std, hyp_rb, hyp_stdb = [], [], [], []\n",
    "ngrid = 0\n",
    "for trial_params in tqdm(grid, desc='Hyperparameters', leave=False):\n",
    "    \n",
    "    (r, r_b), (std, std_b) = ntrials(3, 10, env_, None, agent.policy.state_dict(), **trial_params)\n",
    "    \n",
    "    hyp_r.append(r)\n",
    "    hyp_rb.append(r_b)\n",
    "    hyp_std.append(std)\n",
    "    hyp_stdb.append(std_b)\n",
    "    ngrid += 1\n",
    "    \n",
    "    fname = pth + env_name + '_' + \\\n",
    "            sanitize_filename(str({k:v for k,v in trial_params.items() if not k.startswith('library')}))\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plot_adaption((r, r_b), (std, std_b), ('e-MAML', 'Vanilla RL'));\n",
    "    plt.savefig(fname + '.png')\n",
    "    with open(fname+'.pickle', 'wb') as f:\n",
    "        pickle.dump(dict(trial_params=trial_params, results=(r, r_b, std, std_b)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for trial_params, r, r_b, std, std_b in tqdm(zip(grid, hyp_r, hyp_std, hyp_rb, hyp_stdb), leave=False, total=len(grid)):\n",
    "    \n",
    "    fname = pth + env_name + '_' + \\\n",
    "            sanitize_filename(str({k:v for k,v in trial_params.items() if not k.startswith('library')}))\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plot_adaption((r, r_b), (std, std_b), ('e-MAML', 'Vanilla RL'));\n",
    "    plt.savefig(fname + '.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    i+=1\n",
    "    if i==2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ncol = 2\n",
    "nrow = ngrid // ncol + (ngrid % ncol != 0)\n",
    "plt.figure(figsize=(12, 3 * nrow))\n",
    "for i, (grid_params, (r, r_b, std, std_b)) in enumerate(zip(grid, zip(hyp_r, hyp_rb, hyp_std, hyp_stdb))):\n",
    "    plt.subplot(nrow, ncol, i + 1)\n",
    "    plot_adaption((r, r_b), (std, std_b), ('e-MAML', 'Vanilla RL'));\n",
    "    print([(k, len(v) if k=='library' else v) for k, v in grid_params.items() if k not in ['post_steps']])\n",
    "    plt.title(i)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Performance-weighed sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Most favorable policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = PPO(env_, **ppo_params)\n",
    "a.policy.load_state_dict(agent.policy.state_dict())\n",
    "m = Memory()\n",
    "a.experience(m, ppo_params['update_interval'], env_, a.policy)\n",
    "\n",
    "ret = torch.tensor(returns(m.rewards, m.is_terminals, a.gamma)).float().to(DEVICE)\n",
    "ret = (ret - ret.mean()) / (ret.std() + 1e-5)\n",
    "states = torch.tensor(m.states).float().to(DEVICE).detach()\n",
    "actions = torch.tensor(m.actions).float().to(DEVICE).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args, vals = rank_policies(m, library, **ppo_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.asarray(vals)[args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pth = f'./bin/{env_name}/rnd_vs_lib/'\n",
    "os.makedirs(pth, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trial_params = dict(\n",
    "    alpha_inner = 1e-3,\n",
    "    alpha_outer = 2e-3,\n",
    "    n_inner = 3,\n",
    "    n_outer = 3,\n",
    "    interactive_env = False,\n",
    "    post_steps = 30000,\n",
    "    library = library,\n",
    "    library_grads = library_grads,\n",
    "    mode = 'maml',\n",
    "    rank = 2,\n",
    "    benchmark=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env_.reset()\n",
    "(r, r_m, r_v), (std, std_m, std_v) = ntrials(1, 20, env_, None, agent.policy.state_dict(), **trial_params)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_adaption((r, r_m, r_v), (std, std_m, std_v), ('e-MAML', 'MAML', 'Vanilla RL'))\n",
    "\n",
    "fname = pth + env_name + '_' + sanitize_filename(str({k:v for k,v in trial_params.items() if not k.startswith('library')}))\n",
    "\n",
    "# plt.savefig(fname + '.png')\n",
    "# with open(fname+'.pickle', 'wb') as f:\n",
    "#     pickle.dump(dict(trial_params=trial_params, results=((r, r_m, r_v), (std, std_m, std_v))), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trial_params['rank'] = -1\n",
    "trial_params['benchmark'] = False\n",
    "\n",
    "env_.reset()\n",
    "(r2,), (std2,) = ntrials(1, 20, env_, None, agent.policy.state_dict(), **trial_params)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_adaption((r2, r, r_v), (std2, std, std_v), ('e-MAML (4)', 'e-MAML(2)', 'Vanilla RL'));\n",
    "\n",
    "fname = pth + env_name + '_' + sanitize_filename(str({k:v for k,v in trial_params.items() if  not k.startswith('library')}))\n",
    "\n",
    "# plt.savefig(fname + '.png')\n",
    "# with open(fname+'.pickle', 'wb') as f:\n",
    "#     pickle.dump(dict(trial_params=trial_params, results=(r, r_b, std, std_b)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plot_adaption((r2, r, r_m, r_v), (std2, std, std_m, std_v), ('e-MAML (rank=4)', 'e-MAML (rank=2)', 'MAML', 'Vanilla RL'))\n",
    "plt.title('Performance-weighed sampling comparison')\n",
    "plt.tight_layout()\n",
    "fname = pth + env_name + '_' + 'rank_comparison'\n",
    "plt.savefig(fname + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Policy complement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Learning complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comp = []\n",
    "comp_rewards = []\n",
    "comp_envs = []\n",
    "\n",
    "e_params = [\n",
    "        dict(resistances=[100, 100, 100, 70,  80,   90], pumps=[0.1, 0.1, 0.1, 0.,  0.1, 0.1], engines=[0.05, 0.1]),\n",
    "        dict(resistances=[100, 100, 100, 70,  80,   90], pumps=[0. , 0.1, 0.1, 0.,  0.1, 0.1], engines=[0.05, 0.1]),\n",
    "        dict(resistances=[100, 100, 100, 150, 200, 100], pumps=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1], engines=[0.1, 0.05]),\n",
    "        dict(resistances=[100, 100, 100, 150, 200, 100], pumps=[0.1, 0.1, 0.1, 0.1, 0. , 0. ], engines=[0.1, 0.05]),\n",
    "        dict(resistances=[90,  100, 100, 70,   80,  90], pumps=[0.1, 0.1, 0.,  0.1, 0.1, 0.1], engines=[0.05, 0.1]),\n",
    "        dict(resistances=[90,  100, 100, 70,   80,  90], pumps=[0. , 0.1, 0.,  0.1, 0.1, 0. ], engines=[0.05, 0.1]),\n",
    "        dict(resistances=[100,  75, 100, 100,  75, 100], pumps=[0.1, 0. , 0.1, 0.1, 0.1, 0.1], engines=[0.05, 0.1]),\n",
    "]\n",
    "for e_param in e_params:\n",
    "    e = env_fn()\n",
    "    e.set_parameters(**e_param)\n",
    "    comp_envs.append(e)\n",
    "\n",
    "# factors = [random_degrade(**nominal_config) for _ in range(3)]\n",
    "\n",
    "for e in tqdm(comp_envs, leave=False):\n",
    "    agent_ = PPO(e, **ppo_params)\n",
    "    agent_.policy.load_state_dict(copy_tensor(agent.policy.state_dict()))\n",
    "    rewards = agent_.learn(50000, track_higher_gradients=False)\n",
    "    comp.append(copy_tensor(agent_.policy.state_dict()))\n",
    "    comp_rewards.append(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = PPO(env, **ppo_params)\n",
    "a.policy.load_state_dict(agent.policy.state_dict())\n",
    "m = Memory()\n",
    "a.experience(m, ppo_params['update_interval'], env, a.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comp_, divmat, idx = prune_library(comp, library_size, m, **ppo_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "divmat.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pth = f'./bin/{env_name}/complement/'\n",
    "os.makedirs(pth, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trial_params = dict(\n",
    "    alpha_inner = 1e-3,\n",
    "    alpha_outer = 2e-3,\n",
    "    n_inner = 3,\n",
    "    n_outer = 3,\n",
    "    interactive_env = False,\n",
    "    post_steps = 30000,\n",
    "    library = comp_,\n",
    "    library_grads = None,\n",
    "    mode = 'fomaml',\n",
    "    rank = -1,\n",
    "    benchmark=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env_.reset()\n",
    "(r, r_m, r_v), (std, std_m, std_v) = ntrials(1, 20, env_, None, agent.policy.state_dict(), **trial_params)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_adaption((r, r_m, r_v), (std, std_m, std_v), ('e-MAML(most divergent)', 'MAML', 'Vanilla RL'))\n",
    "\n",
    "fname = pth + env_name + '_' + sanitize_filename(str({k:v for k,v in trial_params.items() if not k.startswith('library')}))\n",
    "\n",
    "# plt.savefig(fname + '.png')\n",
    "# with open(fname+'.pickle', 'wb') as f:\n",
    "#     pickle.dump(dict(trial_params=trial_params, results=((r, r_m, r_v), (std, std_m, std_v))), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trial_params['library'] = [comp[i] for i in range(len(comp)) if i not in idx[0][1]]\n",
    "trial_params['rank'] = -1\n",
    "trial_params['benchmark'] = False\n",
    "\n",
    "env_.reset()\n",
    "(r2,), (std2,) = ntrials(1, 20, env_, None, agent.policy.state_dict(), **trial_params)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_adaption((r, r2, r_v), (std, std2, std_v), ('e-MAML (most divergent)', 'e-MAML(least divergent)', 'Vanilla RL'));\n",
    "\n",
    "fname = pth + env_name + '_' + sanitize_filename(str({k:v for k,v in trial_params.items() if  not k.startswith('library')}))\n",
    "\n",
    "# plt.savefig(fname + '.png')\n",
    "# with open(fname+'.pickle', 'wb') as f:\n",
    "#     pickle.dump(dict(trial_params=trial_params, results=(r, r_b, std, std_b)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plot_adaption((r, r2, r_m, r_v), (std, std2, std_m, std_v), ('e-MAML (4 most divergent)', 'e-MAML (3 least divergent)', 'MAML', 'Vanilla RL'))\n",
    "plt.title('Complement divergence comparison')\n",
    "plt.tight_layout()\n",
    "fname = pth + env_name + '_' + 'divergence_comparison'\n",
    "plt.savefig(fname + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## $\\Delta \\theta$ Approximations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pth = f'./bin/{env_name}/deltatheta/'\n",
    "os.makedirs(pth, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trial_params = dict(\n",
    "    alpha_inner = 1e-3,\n",
    "    alpha_outer = 2e-3,\n",
    "    n_inner = 3,\n",
    "    n_outer = 3,\n",
    "    interactive_env = False,\n",
    "    post_steps = 30000,\n",
    "    library = library,\n",
    "    library_grads = library_grads,\n",
    "    mode = 'maml',\n",
    "    rank = 2,\n",
    "    benchmark=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env_.reset()\n",
    "(r, r_m, r_v), (std, std_m, std_v) = ntrials(1, 20, env_, None, agent.policy.state_dict(), **trial_params)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_adaption((r, r_v), (std, std_v), ('MAML', 'Vanilla RL'))\n",
    "\n",
    "fname = pth + env_name + '_' + sanitize_filename(str({k:v for k,v in trial_params.items() if not k.startswith('library')}))\n",
    "\n",
    "# plt.savefig(fname + '.png')\n",
    "# with open(fname+'.pickle', 'wb') as f:\n",
    "#     pickle.dump(dict(trial_params=trial_params, results=((r, r_m, r_v), (std, std_m, std_v))), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trial_params['mode'] = 'fomaml'\n",
    "trial_params['benchmark'] = False\n",
    "\n",
    "env_.reset()\n",
    "(r2,), (std2,) = ntrials(1, 20, env_, None, agent.policy.state_dict(), **trial_params)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_adaption((r, r2, r_v), (std, std2, std_v), ('MAML', 'FOMAML', 'Vanilla RL'));\n",
    "\n",
    "fname = pth + env_name + '_' + sanitize_filename(str({k:v for k,v in trial_params.items() if  not k.startswith('library')}))\n",
    "\n",
    "# plt.savefig(fname + '.png')\n",
    "# with open(fname+'.pickle', 'wb') as f:\n",
    "#     pickle.dump(dict(trial_params=trial_params, results=(r, r_b, std, std_b)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trial_params['mode'] = 'reptile'\n",
    "trial_params['benchmark'] = False\n",
    "\n",
    "env_.reset()\n",
    "(r3,), (std3,) = ntrials(1, 20, env_, None, agent.policy.state_dict(), **trial_params)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_adaption((r, r2, r_v), (std, std2, std_v), ('e-MAML (most divergent)', 'e-MAML(least divergent)', 'Vanilla RL'));\n",
    "\n",
    "fname = pth + env_name + '_' + sanitize_filename(str({k:v for k,v in trial_params.items() if  not k.startswith('library')}))\n",
    "\n",
    "# plt.savefig(fname + '.png')\n",
    "# with open(fname+'.pickle', 'wb') as f:\n",
    "#     pickle.dump(dict(trial_params=trial_params, results=(r, r_b, std, std_b)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plot_adaption((r, r2, r3), (std, std2, std3), ('MAML', 'FOMAML', 'REPTILE'))\n",
    "plt.title('Update step approximation comparison')\n",
    "plt.tight_layout()\n",
    "fname = pth + env_name + '_' + 'deltatheta_comparison_' + ('ranked' if trial_params['rank'] > 0 else 'unranked')\n",
    "plt.savefig(fname + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
