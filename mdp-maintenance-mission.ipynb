{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous work (scroll down and start below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(i, j, k, K, n, t, v):\n",
    "    first = \"i: {}\\tj: {}\\tn: {}\\tT(k,j,n): {}\\tV(k): {}\".format(i, j, n, t, v)\n",
    "    others = \"T(k,j,n): {}\\tV(k): {}\".format(t, v)\n",
    "    if(k == 0):\n",
    "        print(first, end=\"\")\n",
    "    else:\n",
    "        print(others, end=\"\")\n",
    "    if(k != K):\n",
    "        print(\" +\\t\", end=\"\")\n",
    "    else:\n",
    "        print(\"\")\n",
    "\n",
    "def value_iteration(states, actions, T, rewards, gamma, beta, values=[], verbose=False):\n",
    "    \"\"\"\n",
    "        @brief: implements Bellman's equation to assign the max expected state values\n",
    "        \n",
    "        @input:\n",
    "            states: a list of states (length is j), type should be string if verbose=True i.e. [\"s1\", \"s2\", \"living room\" ... \"etc\"]\n",
    "            actions: a list of actions (length is n), type should be string if verbose=True i.e. [\"a1\", \"a2\", \"take picture\" ... \"etc\"]\n",
    "            T: a jxjxn matrix of transition probabilities P(Sj | Si, An) for all Sj, Si, and An, j=i is valid (self transitions)\n",
    "            rewards: an array of length j specifying the reward for each state. The reward value never changes.\n",
    "            gamma: the discount factor, i.e. how much do we care about future rewards\n",
    "            beta: the stopping criteria, i.e. minimum amount of improvement between iterations before stopping\n",
    "            values: [optional] current values of the states, set to the states reward value if not supplied\n",
    "            verbose: [optional] set to false \n",
    "        \n",
    "        @output:\n",
    "            values: an array of state values where V(S(i)) = V[i]\n",
    "            policy: a dictionary mapping states as keys to the best action as values, i.e. policy[\"some state\"] -> \"some action\"\n",
    "    \"\"\"\n",
    "    if(len(values) == 0):\n",
    "        values = rewards[:]\n",
    "    old_values = np.ones(len(rewards))*-999\n",
    "    #stopping_criteria = .005\n",
    "    policy = dict.fromkeys(states, \"\")\n",
    "    i = 0\n",
    "    while(abs(sum(values) - sum(old_values)) > beta):\n",
    "        old_values = values[:]\n",
    "        for j in range(0, len(states)): # all states in S\n",
    "            vals = np.zeros(len(actions))\n",
    "            for n in range(0, len(actions)): # valid actions in Sj\n",
    "                assert vals[n] == 0\n",
    "                for k in range(0, len(states)): # reachabe states from Sj\n",
    "                    vals[n] = vals[n] + T[k][j][n]*values[k]\n",
    "                    if(verbose):\n",
    "                        debug(i, j, k, len(states)-1, n, T[k][j][n], values[k])\n",
    "            values[j] = rewards[j] + gamma * np.amax(vals)\n",
    "            policy[states[j]] = actions[np.argmax(vals)]\n",
    "            if(verbose):\n",
    "                print(\"Vals: {}\".format(vals))\n",
    "                print(\"V({0}) = R({0}) + gamma*max({1})\".format(j, vals))\n",
    "                print(\"V({0}) = {1} + {2}*{3}\".format(j, rewards[j], gamma, np.amax(vals)))\n",
    "                print(\"V(\" + str(j) + \"): \" + str(values[j]))\n",
    "        i = i + 1\n",
    "    print(\"Stopping criteria met. state values have been permanently assigned.\")\n",
    "    print(\"V(s1) = {:.2f}\\tV(s2) = {:.2f}\".format(values[0], values[1]))\n",
    "    print(\"R(s1) = {:.2f}\\tR(s2) = {:.2f}\".format(rewards[0], rewards[1]))\n",
    "    print(\"Optimal policy: \")\n",
    "    for key, value in policy.items():\n",
    "        print(\"in state (\" + key + \") take action (\" + value+ \")\")\n",
    "    return values, policy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contrived example for understanding value iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping criteria met. state values have been permanently assigned.\n",
      "V(s1) = 4.40\tV(s2) = 1.20\n",
      "R(s1) = 3.00\tR(s2) = -1.00\n",
      "Optimal policy: \n",
      "in state (s1) take action (a2)\n",
      "in state (s2) take action (a1)\n",
      "[4.399061441421509, 1.1995307207107544]\n",
      "{'s1': 'a2', 's2': 'a1'}\n"
     ]
    }
   ],
   "source": [
    "#### dont change anything in this cell, just comment out if needed.\n",
    "states = [\"s1\", \"s2\"]\n",
    "actions = [\"a1\", \"a2\"]\n",
    "rewards = [3, -1]\n",
    "\n",
    "# initialize the values\n",
    "# possible choices are random, zeros, or set to reward value\n",
    "values = rewards[:]\n",
    "\n",
    "# T is a jxjxn matrix of transition probabilities P(Sj | Si, An) for all Sj, Si, and An\n",
    "# P(s1 | s1, a1) = 0.0\n",
    "# P(s1 | s1, a2) = 0.5 \n",
    "# .... \n",
    "# P(s2 | s2, a2) = 1.0\n",
    "# This information must be given (or learned, but that is a different problem)\n",
    "T = [[[0, .5], [1.0, 0]], [[1.0, .5], [0, 1.0]]]\n",
    "\n",
    "# the weight factor for how much we care about future rewards\n",
    "gamma = .5\n",
    "\n",
    "# the stopping criteria, i.e. if improvement is less than this value then stop\n",
    "beta = .005\n",
    "values, policy = value_iteration(states, actions, T, rewards[:], gamma, beta, values=rewards[:], verbose=False)\n",
    "print(values)\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-value iteration for prognostics scheduling\n",
    "#### valid actions are \n",
    "    - maintenance \n",
    "    - short mission\n",
    "    - long mission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1647,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions(state, actions):\n",
    "    \"\"\"\n",
    "        @brief: maps a given state to the valid actions in that state\n",
    "        \n",
    "        @input:\n",
    "            states: a list of states (length is i), type should be string if verbose=True i.e. [\"s1\", \"s2\", \"living room\" ... \"etc\"]\n",
    "            actions: a list of actions (length is j), type should be string if verbose=True i.e. [\"a1\", \"a2\", \"take picture\" ... \"etc\"]\n",
    "        \n",
    "        @output:\n",
    "            valid_actions: an array of valid actions for a given state\n",
    "    \"\"\"\n",
    "    valid_actions = []\n",
    "    if(state == \"dead\"):\n",
    "        valid_actions = [\"maintenance\"]\n",
    "    else:\n",
    "        valid_actions = actions\n",
    "    return valid_actions\n",
    "\n",
    "\n",
    "\n",
    "def build_T(states, actions, verbose=False):\n",
    "    \"\"\"\n",
    "        @brief: constructs the transition matrix\n",
    "        \n",
    "        @input:\n",
    "            states: a list of states (length is i and k where i==k), [\"healthy\", \"good\", \"degraded\", \"dead\"]\n",
    "            actions: a list of actions (length is j), [\"maintenance\", \"short-mission\", \"long-mission\"]\n",
    "        \n",
    "        @output:\n",
    "            T: an [i,j,k] shape matrix where T[i,j,k] = probability of transition to state k from state i taking action j\n",
    "    \"\"\"\n",
    "    T = np.zeros((len(states), len(actions), len(states)))\n",
    "    for i in range(0, len(states)):\n",
    "        current_state = states[i]\n",
    "        valid_actions = get_actions(current_state, actions)\n",
    "        for j in range(0, len(valid_actions)):\n",
    "            action = valid_actions[j]\n",
    "            for k in range(0, len(states)):\n",
    "                next_state = states[k]\n",
    "                if(current_state == \"healthy\"):\n",
    "                    if(action == \"maintenance\"):\n",
    "                        if(next_state == \"healthy\"):\n",
    "                            T[i,j,k] = 1.0\n",
    "                    elif(action == \"short-mission\"):\n",
    "                        if(next_state == \"healthy\"):\n",
    "                            T[i,j,k] = .99\n",
    "                        elif(next_state == \"good\"):\n",
    "                            T[i,j,k] = .01\n",
    "                    elif(action == \"long-mission\"):\n",
    "                        if(next_state == \"healthy\"):\n",
    "                            T[i,j,k] = .9\n",
    "                        elif(next_state == \"good\"):\n",
    "                            T[i,j,k] = .09\n",
    "                        elif(next_state == \"degraded\"):\n",
    "                            T[i,j,k] = .01\n",
    "                            \n",
    "                elif(current_state == \"good\"):\n",
    "                    if(action == \"maintenance\"):\n",
    "                        if(next_state == \"healthy\"):\n",
    "                            T[i,j,k] = .9\n",
    "                        elif(next_state == \"good\"):\n",
    "                            T[i,j,k] = .1\n",
    "                    elif(action == \"short-mission\"):\n",
    "                        if(next_state == \"good\"):\n",
    "                            T[i,j,k] = .9\n",
    "                        elif(next_state == \"degraded\"):\n",
    "                            T[i,j,k] = .1\n",
    "                    elif(action == \"long-mission\"):\n",
    "                        if(next_state == \"good\"):\n",
    "                            T[i,j,k] = .8\n",
    "                        elif(next_state == \"degraded\"):\n",
    "                            T[i,j,k] = .2\n",
    "\n",
    "                elif(current_state == \"degraded\"):\n",
    "                    if(action == \"maintenance\"):\n",
    "                        if(next_state == \"healthy\"):\n",
    "                            T[i,j,k] = .05\n",
    "                        elif(next_state == \"good\"):\n",
    "                            T[i,j,k] = .75\n",
    "                        elif(next_state == \"degraded\"):\n",
    "                            T[i,j,k] = .2\n",
    "                    elif(action == \"short-mission\"):\n",
    "                        if(next_state == \"degraded\"):\n",
    "                            T[i,j,k] = .7\n",
    "                        elif(next_state == \"dead\"):\n",
    "                            T[i,j,k] = .3\n",
    "                    elif(action == \"long-mission\"):\n",
    "                        if(next_state == \"degraded\"):\n",
    "                            T[i,j,k] = .05\n",
    "                        elif(next_state == \"dead\"):\n",
    "                            T[i,j,k] = .95\n",
    "\n",
    "                elif(current_state == \"dead\"):\n",
    "                    if(action == \"maintenance\"):\n",
    "                        if(next_state == \"dead\"):\n",
    "                            T[i,j,k] = .2\n",
    "                        elif(next_state == \"degraded\"):\n",
    "                            T[i,j,k] = .65\n",
    "                        elif(next_state == \"good\"):\n",
    "                            T[i,j,k] = .15\n",
    "                                     \n",
    "                if(verbose):\n",
    "                    print(\"P({} | {} , {}): {}\".format(next_state, current_state, action, T[i,j,k]))\n",
    "    return T\n",
    "    \n",
    "    \n",
    "def build_R(states, actions, rewards, verbose=False):\n",
    "    \"\"\"\n",
    "        @brief: constructs the reward matrix\n",
    "        \n",
    "        @input:\n",
    "            states: a list of states (length is i and k where i==k), [\"healthy\", \"good\", \"degraded\", \"dead\"]\n",
    "            actions: a list of actions (length is j), [\"maintenance\", \"short-mission\", \"long-mission\"]\n",
    "            rewards: a dictionary of rewards mapping quantitative values to qualitative expressions\n",
    "        \n",
    "        @output:\n",
    "            R: an [i,j] shape matrix where R[i,j] = reward for being in state i and taking action j\n",
    "    \"\"\"\n",
    "    R = np.zeros((len(states), len(actions)))\n",
    "    for i in range(0, len(states)):\n",
    "        state = states[i]\n",
    "        for j in range(0, len(actions)):\n",
    "            action = actions[j]\n",
    "            if(state == \"healthy\"):\n",
    "                if(action == \"maintenance\"):\n",
    "                    R[i,j] = rewards[\"bad\"]\n",
    "                elif(action == \"short-mission\"):\n",
    "                    R[i,j] = rewards[\"good\"]\n",
    "                elif(action == \"long-mission\"):\n",
    "                    R[i,j] = rewards[\"best\"]\n",
    "\n",
    "            elif(state == \"good\"):\n",
    "                if(action == \"maintenance\"):\n",
    "                    R[i,j] = rewards[\"none\"]\n",
    "                elif(action == \"short-mission\"):\n",
    "                    R[i,j] = rewards[\"best\"]\n",
    "                elif(action == \"long-mission\"):\n",
    "                    R[i,j] = rewards[\"good\"]\n",
    "  \n",
    "            elif(state == \"degraded\"):\n",
    "                if(action == \"maintenance\"):\n",
    "                    R[i,j] = rewards[\"best\"]\n",
    "                elif(action == \"short-mission\"):\n",
    "                    R[i,j] = rewards[\"bad\"]\n",
    "                elif(action == \"long-mission\"):\n",
    "                    R[i,j] = rewards[\"worst\"]\n",
    "  \n",
    "            elif(state == \"dead\"):\n",
    "                if(action == \"maintenance\"):\n",
    "                    R[i,j] = rewards[\"none\"]\n",
    "                else:\n",
    "                    R[i,j] = -99\n",
    "                    \n",
    "            if(verbose):\n",
    "                print(\"R({} + {}): {}\".format(state, action, R[i,j]))\n",
    "    return R\n",
    "\n",
    "def get_reward(state, action, rewards):\n",
    "    \"\"\"\n",
    "        @brief: returns the reward value for a given state-action pair\n",
    "        \n",
    "        @input:\n",
    "            states: a list of states (length is i and k where i==k), [\"healthy\", \"good\", \"degraded\", \"dead\"]\n",
    "            actions: a list of actions (length is j), [\"maintenance\", \"short-mission\", \"long-mission\"]\n",
    "            rewards: a dictionary of rewards mapping quantitative values to qualitative expressions\n",
    "        \n",
    "        @output:\n",
    "            a real number reward value\n",
    "    \"\"\"\n",
    "    if(state == \"healthy\"):\n",
    "        if(action == \"maintenance\"):\n",
    "            return rewards[\"bad\"]\n",
    "        elif(action == \"short-mission\"):\n",
    "            return rewards[\"good\"]\n",
    "        elif(action == \"long-mission\"):\n",
    "            return rewards[\"best\"]\n",
    "        else:\n",
    "            return -9999 \n",
    "    elif(state == \"good\"):\n",
    "        if(action == \"maintenance\"):\n",
    "            return rewards[\"none\"]\n",
    "        elif(action == \"short-mission\"):\n",
    "            return rewards[\"best\"]\n",
    "        elif(action == \"long-mission\"):\n",
    "            return rewards[\"good\"]\n",
    "        else:\n",
    "            return -9999    \n",
    "    elif(state == \"degraded\"):\n",
    "        if(action == \"maintenance\"):\n",
    "            return rewards[\"best\"]\n",
    "        elif(action == \"short-mission\"):\n",
    "            return rewards[\"bad\"]\n",
    "        elif(action == \"long-mission\"):\n",
    "            return rewards[\"worst\"]\n",
    "        else:\n",
    "            return -9999   \n",
    "    elif(state == \"dead\"):\n",
    "        if(action == \"maintenance\"):\n",
    "            return rewards[\"none\"]\n",
    "        elif(action == \"short-mission\"):\n",
    "            return rewards[\"worst\"]\n",
    "        elif(action == \"long-mission\"):\n",
    "            return rewards[\"worst\"]\n",
    "        else:\n",
    "            return -9999       \n",
    "    else:\n",
    "        return -9999\n",
    "\n",
    "\n",
    "def q_iteration(states, actions, T, R, Q, gamma, epsilon, verbose=False):\n",
    "    \"\"\"\n",
    "        @brief: implements Bellman's equation to solve for Q\n",
    "        \n",
    "        @input:\n",
    "            states: a list of states (length is i and k where i==k), [\"healthy\", \"good\", \"degraded\", \"dead\"]\n",
    "            actions: a list of actions (length is j), [\"maintenance\", \"short-mission\", \"long-mission\"]\n",
    "            T: a ixjxk matrix of transition probabilities P(Sk | Si, An) for all Sk, Si, and An\n",
    "            R: an ixj matrix of reward values \n",
    "            Q: an ixj matrix of Q values for a given state action pair (typically 0s to start)\n",
    "            gamma: the discount factor, i.e. how much do we care about future rewards\n",
    "            epsilon: the stopping criteria, i.e. minimum amount of improvement between iterations before stopping\n",
    "        \n",
    "        @output:\n",
    "            Q: an ixj matrix of Q values \n",
    "            policy: a dictionary mapping states as keys to the best action as values, i.e. policy[\"some state\"] -> \"some action\"\n",
    "    \"\"\"\n",
    "    old_Q = np.ones(R.shape)* -999\n",
    "    epsilon = .1\n",
    "    c = 0\n",
    "    policy = dict.fromkeys(states, \"\")\n",
    "    while(abs(sum(sum(Q)) - sum(sum(old_Q))) > epsilon):\n",
    "        old_Q[:] = Q[:]\n",
    "        for i in range(0, len(states)):\n",
    "            current_state = states[i]\n",
    "            actions = get_actions(state, actions)\n",
    "            for j in range(0, len(actions)):\n",
    "                current_action = actions[j]\n",
    "                q_vals =np.zeros(len(states))\n",
    "                for k in range(0, len(states)):\n",
    "                    next_state = states[k]\n",
    "                    reward = get_reward(current_state, current_action, rewards)\n",
    "                    if(verbose):\n",
    "                        print(\"s[{}]: {}, a[{}]: {}, R: {} \\t s'[{}]: {}, oldQ[s']: {}\".format(i, current_state, j, current_action, reward, k, next_state, old_Q[k]))\n",
    "                    q_vals[k] = T[i,j,k] * (reward + gamma * np.amax(old_Q[k]))\n",
    "                Q[i,j] = np.sum(q_vals)\n",
    "                if(verbose):\n",
    "                    print(\"Q[{},{}]: {}\".format(current_state, current_action, Q[i,j]))\n",
    "            policy[states[i]] = actions[np.argmax(Q[i])]\n",
    "        c+=1\n",
    "    if(verbose):\n",
    "        print(\"Optimal policy: \")\n",
    "        for key, value in policy.items():\n",
    "            print(\"in state (\" + key + \") take action (\" + value+ \")\")\n",
    "    return Q, policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.99414062  3.99414062  5.99414062]\n",
      " [ 2.99414062  5.99414062  3.99414062]\n",
      " [ 5.99414062  1.49414063 -1.58919271]\n",
      " [ 2.66080729  0.          0.        ]]\n",
      "in state (healthy) take action (long-mission)\n",
      "in state (good) take action (short-mission)\n",
      "in state (degraded) take action (maintenance)\n",
      "in state (dead) take action (maintenance)\n"
     ]
    }
   ],
   "source": [
    "states = [\"healthy\", \"good\", \"degraded\", \"dead\"]\n",
    "actions = [\"maintenance\", \"short-mission\", \"long-mission\"]\n",
    "# best action, ok action, nothing action, crappy action, worst action\n",
    "rewards = {\n",
    "    \"best\"  :  3,\n",
    "    \"good\"  :  1,\n",
    "    \"none\"   :  0,\n",
    "    \"bad\"   : -1,\n",
    "    \"worst\" : -3\n",
    "}\n",
    "\n",
    "gamma = .5\n",
    "epsilon = .01\n",
    "\n",
    "T = build_T(states, actions)\n",
    "R = build_R(states, actions, rewards)\n",
    "Q = np.zeros(R.shape)\n",
    "\n",
    "Q, policy = q_iteration(states, actions, T, R, Q, gamma, epsilon, verbose=False)\n",
    "print(Q)\n",
    "for key, value in policy.items():\n",
    "    print(\"in state (\" + key + \") take action (\" + value+ \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max iterations reached\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('healthy', 'long-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('degraded', 'maintenance')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('degraded', 'maintenance')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('degraded', 'maintenance')\n",
      "('degraded', 'maintenance')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('degraded', 'maintenance')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('degraded', 'maintenance')\n",
      "('degraded', 'maintenance')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('degraded', 'maintenance')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('degraded', 'maintenance')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('degraded', 'maintenance')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n",
      "('good', 'short-mission')\n"
     ]
    }
   ],
   "source": [
    "# define max iterations\n",
    "max_iterations = 1000\n",
    "\n",
    "# start in healthy state\n",
    "state = states[0]\n",
    "\n",
    "# create an empty history list (tuple of state-action pairs)\n",
    "history = []\n",
    "i = 0\n",
    "\n",
    "### -----------------------------\n",
    "\n",
    "# simulate until the craft dies (hopefully, it should never happen!)\n",
    "while(state is not \"dead\"):\n",
    "    # get the current best action\n",
    "    action = policy[state]\n",
    "    \n",
    "    # stochasticity\n",
    "    r = np.random.uniform(0.000, 1.0000001)\n",
    "    \n",
    "    # grab the transition probabilities for the current state-action pair\n",
    "    # P is an array where the indicies are the indicies of the next state\n",
    "    # and the values are the probabiliity of transitioning into that state\n",
    "    P = T[states.index(state), actions.index(action)]\n",
    "    \n",
    "    # put them in order for the probability calculate\n",
    "    Ps = np.flip(np.argsort(P))\n",
    "\n",
    "    # find out what state the system transitions to\n",
    "    if(r <= P[Ps[0]]):\n",
    "        next_state = states[Ps[0]]\n",
    "    elif(r <= (P[Ps[0]] + P[Ps[1]])):\n",
    "        next_state = states[Ps[1]]\n",
    "    elif(r <= (P[Ps[0]] + P[Ps[1]] + P[Ps[2]])):\n",
    "        next_state = states[Ps[2]]\n",
    "    else:\n",
    "        next_state = states[Ps[3]]\n",
    "        \n",
    "    # append the current state-action pair to the history\n",
    "    history.append((state, action))\n",
    "    \n",
    "    # assign to current state\n",
    "    state = next_state\n",
    "    \n",
    "    # useful to stop the loop as the model is defined in such a way as to have a\n",
    "    # very small probability of reaching the dead state\n",
    "    i += 1\n",
    "    if(i == max_iterations):\n",
    "        break\n",
    "\n",
    "### -----------------------------\n",
    "\n",
    "if(i == max_iterations):\n",
    "    print(\"max iterations reached\")\n",
    "else:\n",
    "    print(\"the uav died!\")\n",
    "for i in range(0, min(100, max_iterations)):\n",
    "    print(history[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1723,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteBattery:\n",
    "    def __init__(self, cells: DiscreteBatteryCell, wiring):\n",
    "        self.cells = cells\n",
    "\n",
    "\n",
    "class DiscreteBatteryCell:\n",
    "    def __init__(self, **kwargs):\n",
    "        if(len(kwargs) == 0):\n",
    "            self.soc_ocv = np.zeros((1,1))\n",
    "            self.R0_degradation = np.zeros((1,1))\n",
    "            self.Q_degradation = np.zeros((1,1))\n",
    "        else:\n",
    "            self.soc_ocv = kwargs[\"soc_ocv\"]\n",
    "            self.R0_degradation = kwargs[\"R0_degradation\"]\n",
    "            self.Q_degradation = kwargs[\"Q_degradation\"]\n",
    "        self.soc = 1.0\n",
    "        self.Ir = 0\n",
    "        self.h = 0\n",
    "        self.M0 = .0019\n",
    "        self.M = .0092\n",
    "        self.R0 = .0112\n",
    "        self.R = 2.83e-4\n",
    "        self.Q = 3.8695\n",
    "        self.n = .9987\n",
    "        self.G = 163.4413\n",
    "        self.v0 = 4.2\n",
    "        self.eod = 3.04\n",
    "        self.RC = 3.6572\n",
    "        self.ocv = self.v0\n",
    "        \n",
    "    def get_ocv(self):\n",
    "        if(self.soc < 0.0):\n",
    "            self.soc = 0\n",
    "        elif(self.soc > 1.0):\n",
    "            self.soc = 1.0\n",
    "        idx = int(np.ceil(self.soc*100))\n",
    "        if(idx > 101):\n",
    "            idx = 101\n",
    "        elif(idx < 1):\n",
    "            idx = 1\n",
    "        return self.soc_ocv[idx]\n",
    "        \n",
    "    def step(self, dt, current):\n",
    "        RC = np.exp(-dt/abs(self.RC))\n",
    "        H = np.exp(-abs(self.n*current*self.G*dt/(3600*self.Q)))\n",
    "        self.Ir = RC*self.Ir + (1-RC)*current\n",
    "        self.h = H*self.h + (H-1)*np.sign(current)\n",
    "        self.soc = self.soc - self.n*current/3600/self.Q\n",
    "        self.ocv = self.get_ocv() + self.M*self.h + self.M0*np.sign(current) - self.R*self.Ir - self.R0*current\n",
    "        \n",
    "    def add_profile(self,**profile):\n",
    "        self.soc_ocv = profile[\"soc_ocv\"]\n",
    "        self.R0_degradation = profile[\"R0_degradation\"]\n",
    "        self.Q_degradation = profile[\"Q_degradation\"]\n",
    "        \n",
    "        \n",
    "def get_battery_curves(soc_ocv_file, R0_degradation_file, Q_degradation_file):\n",
    "    \"\"\"\n",
    "        @brief: gets the degradation profile (predefined curves) for the battery\n",
    "        \n",
    "        @input:\n",
    "            soc_ocv_file: a csv file containing the soc_ocv relationship as a column vector\n",
    "            R0_degradation_file: a csv file containing the R0 degradation curve as a column vector\n",
    "            Q_degradation_file: a csv file containing the Q degradation curve as a column vector\n",
    "        \n",
    "        @output:\n",
    "            a dictionary mapping of degradation curves with [\"soc_ocv\", \"R0_degradation\", \"Q_degradation\"] keys\n",
    "    \"\"\"    \n",
    "    soc_ocv = []\n",
    "    R0_degradation = []\n",
    "    Q_degradation = []\n",
    "    \n",
    "    with open(soc_ocv_file, newline='') as f:\n",
    "        soc_ocv = list(csv.reader(f))\n",
    "    soc_ocv = np.asarray(soc_ocv).astype(np.float)\n",
    "    \n",
    "    with open(R0_degradation_file, newline='') as f:\n",
    "        R0_degradation = list(csv.reader(f))\n",
    "    R0_degradation = np.asarray(R0_degradation).astype(np.float)\n",
    "    \n",
    "    with open(Q_degradation_file, newline='') as f:\n",
    "        Q_degradation = list(csv.reader(f))\n",
    "    Q_degradation = np.asarray(Q_degradation).astype(np.float)\n",
    "    \n",
    "    return {\"soc_ocv\": soc_ocv, \"R0_degradation\": R0_degradation, \"Q_degradation\": Q_degradation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_curves = get_battery_curves('soc_ocv.csv', 'R0_degradation.csv', 'Q_degradation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(3)\n",
    "axes[0].plot(battery_curves[\"soc_ocv\"])\n",
    "axes[1].plot(battery_curves[\"R0_degradation\"])\n",
    "axes[2].plot(battery_curves[\"Q_degradation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2\n",
      "1.0\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "cell = DiscreteBatteryCell(**battery_curves)#soc_ocv, R0_degradation, Q_degradation)\n",
    "print(cell.ocv)\n",
    "print(cell.soc)\n",
    "cell2 = DiscreteBatteryCell()\n",
    "print(cell2.soc_ocv)\n",
    "cell2.add_profile(**battery_curves)\n",
    "battery = DiscreteBattery([DiscreteBatteryCell(), DiscreteBatteryCell(), DiscreteBatteryCell()], \"parallel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.04926653]\n",
      "3569\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while(cell.ocv > (cell.eod * 1.01)):\n",
    "    cell.step(1, 3.8695)\n",
    "    i += 1\n",
    "print(cell.ocv)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 1694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "v = get_ocv(.72, soc_ocv) + M*h + M0*np.sign(u) - R*Ir - R0*u\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1606,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous MDP    \n",
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1607,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(soh):\n",
    "    state = \"\"\n",
    "    if(soh >= 80 and soh <= 100):\n",
    "        state = \"healthy\"\n",
    "    elif(soh >= 65 and soh < 80):\n",
    "        state = \"good\"\n",
    "    elif(soh >= 50 and soh < 65):\n",
    "        state = \"degraded\"\n",
    "    else:\n",
    "        state = \"dead\"\n",
    "    return state\n",
    "        \n",
    "def update_soh(soh, action):\n",
    "    if(action == \"maintenance\"):\n",
    "        soh = soh + 15\n",
    "    elif(action == \"short-mission\"):\n",
    "        soh = soh - .1\n",
    "    elif(action == \"long-mission\"):\n",
    "        soh = soh - .2\n",
    "    else:\n",
    "        soh = soh\n",
    "    return soh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use for continuous\n",
    "# updates after each iteration\n",
    "# soh = 100\n",
    "\n",
    "# number of actions\n",
    "# steps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reward(\"healthy\", \"long-mission\", rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maintenance']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_actions(\"dead\", actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maintenance', 'short-mission', 'long-mission']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'healthy': '', 'good': '', 'degraded': '', 'dead': ''}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = np.zeros(len(states))\n",
    "old_values = np.ones(len(rewards))*-999\n",
    "#stopping_criteria = .005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d3b146d908>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAomElEQVR4nO3dd3hUZdrH8e89qYSakAIICEIIhJ5EepVqAywoSskqC4hYgFWX1Xct69rWLioigiAgYkFBBYXFQhGFBEKTEnqVhBI6JCTP+0cmGNkgITOTM3Pm/lwX15k5M8ncT5RfDvd5znPEGINSSil7cVhdgFJKKffTcFdKKRvScFdKKRvScFdKKRvScFdKKRsKtLoAgMjISFOrVi2ry1BKKZ+Smpp60BgTVdRrXhHutWrVIiUlxeoylFLKp4jIzou9pm0ZpZSyIQ13pZSyIQ13pZSyIQ13pZSyIQ13pZSyoUuGu4hMEpEMEVlXaF+EiCwQkXTnNrzQa/8QkS0isklEeniqcKWUUhdXnCP3yUDPC/aNARYaY2KBhc7niEg80A9o6Pyat0UkwG3VKqWUKpZLhrsxZhFw+ILdvYEpzsdTgD6F9n9kjDlrjNkObAFauKfU/3UmJ5cn56wn49gZT32EUkr5pJL23GOMMfsBnNto5/4rgN2F3rfHue9/iMhQEUkRkZTMzMwSFbF6dxYzlu/ihrFLyDiuAa+UUgXcfUJVithX5N1AjDHvGmOSjDFJUVFFXj17SS2vqsxnw9tw7EwO901fxbEzOSX6PkopZTclDfcDIlIVwLnNcO7fA9Qo9L7qwL6Sl3dpja6oyAu3NCFl52H6jf+ZE2fPefLjlFLKJ5Q03OcAyc7HycDsQvv7iUiIiNQGYoHlrpV4ab2bXcG7A5PY8Nsxer+5hKOn9QheKeXfijMVcgawDIgTkT0iMhh4HugmIulAN+dzjDHrgY+BX4FvgBHGmFxPFV9Y1/gYJt/Vgp2HTvG3j9PIyc0rjY9VSimvJN5wg+ykpCTjrlUhJy/dzpNf/kp81QqMH5hIjYgwt3xfpZTyNiKSaoxJKuo1212h+pe2tXlnQCJ7s04z5IMUTmeXyj8clFLKq9gu3AF6NqrC6/2asenAcZLfX87RU9qDV0r5F1uGO0CnuGhevLUpK3ceYcjUFA6eOGt1SUopVWpsG+4AtyZW58W+TUjbncXwaal6klUp5TdsHe4ANzWvzou3NmHFjiOMnJmmLRqllF/winuoelrvZlew58hpXlmwmbV7jjLnvrZUCgu2uiyllPIY2x+5FxjRuS4zhrRi/9HTjJyZxpkcnUWjlLIvvwl3gBa1I3jixob8sCmTnq8tYtnWQ1aXpJRSHuFX4Q4woNWVTP9rS/IM3DHhZyYs2mZ1SUop5XZ+F+4AbetG8u3IDlzbqArPzN3Am9+lW12SUkq5lV+cUC1KmeAAXrmtGYEBa3hp/mZO5+TyQJdYQgL1xlFKKd/nt+EO+QH/ct+mBAc4eOv7rXy7/gDTBrekSsVQq0tTSimX+GVbprDgQAcv39aUyXddzb6s0wyc+As7D520uiyllHKJ34d7gU5x0YwfmEjG8bMM/SCVU9l60w+llO/ScC+kfWwUb97ZnM0Zx/nLpBVkncq2uiSllCoRDfcLtI+N4qVbm7Jqd/5yBXl51q93r5RSl0vDvQi3JFbncefFTvd/tIrsc7rgmFLKt/j1bJk/M6BlTbJOZvPygs1g4NmbGlMxLMjqspRSqlg03C9CRLi/SywBAcLL8zezZm8Wc0a0I7ysLjimlPJ+2pa5hHs71WXm0FYcOHqWB2emkas9eKWUD9BwL4akWhE80SueRZszGatLFSilfIC2ZYrpzhY1Sd15hNcXplMhNIi729W2uiSllLooDfdiEhGe6dOYrFM5/OurX8kzhsHtaiMiVpemlFL/Q9syl6FMcADjBybSpX40//56A+N+3Iox2oNXSnkfDffLFBTgYMKgJHo2rMJ/vtnEoEnL2Zd12uqylFLqDzTcS8DhEN7un8BTvRqycucRBk78hRNndS0apZT30HAvIYdDSG5TiwnJSWw/eJIxn63RFo1SymtouLuoTZ1IHuoRx1dr9vPo52t1HrxSyivobBk3uKdDHQ6fyOa9JduJKh/K6G71rC5JKeXnNNzdwOEQHru+AUdP5/DGwnSa16hE5/rRVpellPJj2pZxExHh6T6NiK9agWHTUhn3g06TVEpZx6VwF5EHRWSdiKwXkZHOfREiskBE0p3bcLdU6gNCgwL4YHALromL5oVvNvL+0h1Wl6SU8lMlDncRaQQMAVoATYEbRCQWGAMsNMbEAgudz/1GZLkQxg1IoHt8DM/O3UDKjsNWl6SU8kOuHLk3AH42xpwyxpwDfgRuAnoDU5zvmQL0calCHyQivHRbU6qHl2HEhyvJPH7W6pKUUn7GlXBfB3QQkcoiEgZcB9QAYowx+wGc2yLPLIrIUBFJEZGUzMxMF8rwThVCgxg3IJGjp3O4f8ZKveG2UqpUlTjcjTEbgBeABcA3wGqg2AlmjHnXGJNkjEmKiooqaRlerUHVCjx7U2N+3naY7q8uYumWg1aXpJTyEy6dUDXGTDTGJBhjOgCHgXTggIhUBXBuM1wv03fdnFCdj4e1JjjAwaBJy1m+XXvwSinPc3W2TLRzWxO4GZgBzAGSnW9JBma78hl20KJ2BF/c15aaEWGM+HAl6/YetbokpZTNuTrP/TMR+RX4EhhhjDkCPA90E5F0oJvzud+rEBrEOwMSAbhjws/sOnTK4oqUUnbmalumvTEm3hjT1Biz0LnvkDGmizEm1rnVPoRTXJXyzBreBgGGfJDC7sMa8Eopz9ArVEtZjYgw3rwzgX1Zpxkw8RddC14p5REa7hboUC+KyXdfTcaxs3R/dRFTf95Jnq4mqZRyIw13iyReGcH8UR1oVqMS//xiHffPWKVr0Sil3EbD3UI1IsKYOrgFf+tWj6/X7udtXWxMKeUmuuSvxUSE+66py8YDx3nx202cPHuOR3rWt7ospZSP03D3AiLC67c3o2xwAG//sJXTObk8cWNDq8tSSvkwDXcvERjg4JmbGhMSGMD7S3dwLtfwVK+GOBxidWlKKR+k4e5FggIcPNmrIQEOYfJPO6hWqQzDO9WxuiyllA/ScPcyAQ7hiRvjyTxxlhe/3UjTGhVpUyfS6rKUUj5GZ8t4IRHhhVuaUDuyLA/MWMWBY2esLkkp5WM03L1UuZBA3hmQyKnsXIZOTSXjuAa8Uqr4NNy9WGxMeV65rSkb9x9j4HvLOXRC7+iklCoeDXcv17NRVSYMSmLbwRP0eXsph09mW12SUsoHaLj7gA71opgxpBUHjp6l52t6Ryel1KVpuPuIpFoRfDq8NRXKBDFsaiqL0+1331mllPtouPuQJtUr8cHdLYguH8LAict55NPV5OTmWV2WUsoLabj7mGqVyjD3wfbc07EOH6fs4fl5G60uSSnlhfQiJh8UGhTAmGvrcyYnl4lLtlMmKIC/da+HiC5VoJTKp+Huwx69rgHHTufw5vdbyDWGh7vH6Vo0SilAw92nBQc6eKlvU0SEcT9s5VxuHmOubUCABrxSfk/D3cc5HMJLfZsQHChMWLydMzl5upqkUkrD3Q5EhGdvakxoUP5ywSezz/Gy84heKeWfNNxtQkR4/IZ4ygYH8ub3W2heM5yBra60uiyllEV0KqSNiAiju9Wjc1wU//pyPf/99YDVJSmlLKLhbjMOh/Dq7c2oE1WOIVNT+HGzXsmqlD/ScLehSmHBzLq3DXEx5Rn50Sr2Zp22uiSlVCnTcLepsOBAxg1I5Fyu4a73l/PrvmNWl6SUKkUa7jZWO7Is4wYkcvhkNr3eXMKkJdutLkkpVUo03G2uXWwkC0Z1pFNcNE9//Ss/bMqwuiSlVCnQcPcD4WWDGXtH8/we/Mw0dh06ZXVJSikPcyncRWSUiKwXkXUiMkNEQkUkQkQWiEi6cxvurmJVyZUJDmDcgERy8wzXv7GYL1fvs7okpZQHlTjcReQK4AEgyRjTCAgA+gFjgIXGmFhgofO58gK1I8vy5X3tqFelPKNmpjFHA14p23K1LRMIlBGRQCAM2Af0BqY4X58C9HHxM5Qb1Yosy6S/XE2jKyrywIxVfL9Re/BK2VGJw90Ysxd4CdgF7AeOGmPmAzHGmP3O9+wHoov6ehEZKiIpIpKSmakX2pSmimWCmDGkFQ2qVmDkzDR2H9YevFJ240pbJpz8o/TaQDWgrIgMKO7XG2PeNcYkGWOSoqKiSlqGKqEywQGM659AnjHcO30lZ3JyrS5JKeVGrrRlugLbjTGZxpgcYBbQBjggIlUBnFv9d7+XqhVZlpf7NmXt3qM8PnsduXnG6pKUUm7iSrjvAlqJSJjkry3bBdgAzAGSne9JBma7VqLypO4NqzCic/79WG8Z9xMHT5y1uiSllBu40nP/BfgUWAmsdX6vd4HngW4ikg50cz5XXuyh7nG83q8ZG/Yf4/4PV3EuN8/qkpRSLhJjrP+neFJSkklJSbG6DL/3ScpuHv50DdfUj+bt/gmEBgVYXZJS6k+ISKoxJqmo1/QKVXVe36QaPH5DPN9tzODJOeutLkcp5QK9E5P6g7vb1ebQybO89f1WHA7hmT6N9HZ9SvkgDXf1P0Z3i+N0dh6Tlm6nVuUwhnaoY3VJSqnLpOGu/keAQ/jnDQ347dhpXvhmE42qVaRN3Uiry1JKXQbtuasiiQgv3NKEKyuHkfz+chbo/ViV8ika7uqiyocG8ek9bahfpQKjZ6ax4+BJq0tSShWThrv6UxFlgxk3IIGAAOGeaalkHDtjdUlKqWLQcFeXVD08jNf7NWfbwZN0feVHPknZjTdcH6GUujgNd1UsHetFMe/B9tSvUoGHP13Do5+v1YBXyotpuKtiqxNVjo+GtmJYh6uYsXw3037eaXVJSqmL0KmQ6rI4HMIjPeuz4bfj/HP2ek5l5zKso86DV8rb6JG7umwBDuG9QUlc17gKz83byJjP1uh68Ep5GT1yVyUSHOjglduaUTMinfGLtnLsTA4v9W1KWLD+L6WUN9C/iarEQoMCGHNtfcLDgnhu3kbO5OTpapJKeQltyyiXDetYh6d7N+S7jRlc9/pilm8/bHVJSvk9DXflFgNb12La4JZk5+Zx2/hlPD57HTl60w+lLKPhrtymXWwk80d14K62tfhg2U4enbWW09l6olUpK2jPXblVWHAgT9zYkLDgAN76fiurdmfx2T1tqBgWZHVpSvkVPXJXHvFwj/pMubsFOw+d5NZ3fmLVriNWl6SUX9FwVx7TsV4UE5Ov5uTZc9w87ic+SdltdUlK+Q0Nd+VRHepFMX90R9rUqcxjX6wjbXeW1SUp5Rc03JXHlQsJZOwdCUSWDea2d5bx1vdbdCaNUh6m4a5KRUTZYGbf146u8dG8+O0m/jFLV5VUypM03FWpiSofwtv9E7n/mrp8mrqHdxdt04BXykM03FWpG9m1Ht3jY3hu3kbunrxCWzRKeYCGuyp1AQ7hnQGJ/POGeL7flMnz8zZaXZJStqMXMSlLOBzC4Ha12XXoJBOXbOe3o2d49ubGVCyjFzsp5Q4a7spS/7whnugKoby6YDNHT+fw1p0JejWrUm6gbRllqcAAByM61+WZmxqxbNsh7p6iPXil3EHDXXmF26+uyau3NyN15xGem6s9eKVcVeJwF5E4EUkr9OeYiIwUkQgRWSAi6c5tuDsLVvbVq2k1/tKmFpOWbueV+ZvIPqdH8EqVVInD3RizyRjTzBjTDEgETgGfA2OAhcaYWGCh87lSxfLodQ24ufkVvPHdFoZNTeGctmiUKhF3tWW6AFuNMTuB3sAU5/4pQB83fYbyA8GBDl65vRlP9WrI95syGTDxFz2CV6oE3BXu/YAZzscxxpj9AM5ttJs+Q/mR5Da1eP7mxvy87TDPzdtgdTlK+RyXw11EgoFewCeX+XVDRSRFRFIyMzNdLUPZUL8WNbmrbS3eX7qDGct36VIFSl0Gdxy5XwusNMYccD4/ICJVAZzbjKK+yBjzrjEmyRiTFBUV5YYylB3949oGtL6qMv+YtZaRM9PIy9OAV6o43BHud/B7SwZgDpDsfJwMzHbDZyg/FRzoYOrgFjzQJZbZafu4/6NVHDpx1uqylPJ6LoW7iIQB3YBZhXY/D3QTkXTna8+78hlKBQY4GNU1loe612P++t/o9uoi1uzJsrospbyaeEMfMykpyaSkpFhdhvIBm347zt2TVwDw5f3tiCgbbHFFSllHRFKNMUlFvaZXqCqfElelPOMGJJB5/Cy931rCvqzTVpeklFfScFc+p0n1Skz7a0uOnMzh3ukrdR68UkXQcFc+qUXtCF7q24S03Vk88/WvVpejlNfRcFc+q2ejqgxpX5spy3YyO22v1eUo5VU03JVPe6RnfVrUimDMZ2vZfOC41eUo5TU03JVPCwpw8OadzSkbEsidE34hbXeW1SUp5RU03JXPi64QytTBLQgJdHDP1FQO6kVOSmm4K3toULUC7w5K5MipbPq+s4zdh09ZXZJSltJwV7bRsFpF3r/rag6eOEvy+8vZmnnC6pKUsoyGu7KVNnUieXdgElmncrh78go2/aYnWZV/0nBXttO6TmUmDErk+Jlz3DB2Md9tPHDpL1LKZjTclS0lXhnBf0d3pF5MeYZPW8n4H7fqevDKr2i4K9uKKBvM5Lta0LFeFM/N28jEJdutLkmpUqPhrmwtqnwI4wcm0qNhDM/N28jHK3b77RG8jtu/aLgr2xMRXuzblMSa4Tzy2RoGTVrud1Ml//3Vr1zz8o+cycm1upRSN2jScgZPXuF3Ia/hrvxChdAgPhraiqd7N2TlziPc+s5PZB73n4udpv+yi+0HT3Lb+GWcOHvO6nJK1eL0gyzcmMF9M1b51W0aNdyV33A4hIGta/HJPW3IOpXDvdNTOXwy2+qySkVSrXAA1u09Sv/3fiHdj9bhiSofAsDXa/YzfHoqGcfPWFxR6dBwV34nvloF/nNr/nLBAyf+4hetijxjSLwynDfvTGDXoZP0Hb/Mby7yMsZwZ8ua/OPa+ny/KZOuL//Ixyn2P/ei4a78Uu9mVzCufyLr9x3jb5+s5nS2vQM+N88QIMJ1javy+b1tAbj+jcV8lrrH4so8r2DswzrWYd6D7YmrUp5HPl3DwInL2XXIvudeNNyV3+oaH8PDPeL4es1+7p+xytZH8HkGHM6/7bUiy/LNgx1oVqMSf/9sDak7D1tbnIflGQhwCAB1osoxc2hrnu7TiFW7jtDjtUX8tOWgxRV6hoa78msjOtfliRvj+e+GA1z3+mLbBl1ensEhcv55lYqhjB+YRLVKZbh3+kpb96Hz8gyFhp5/7qXVlSwY3ZHq4WW4f8Yq9trwXrwa7srv3dW2NlMHtyA7N487J/xiy4DPNeb80WuBimWCGDcggaxTOVz3+hLmrd1vUXWelWvy2zIXqlapDOMGJHImJ5cb3ljM/PW/WVCd52i4KwW0j43iixFtiSwXQt93lvHc3A2cPWefNk2e4Q9H7gUaVqvIrHvbUKViCMOnr+SBGavItdl0wbwifrEVqBtdjs9HtKV6eBj3fbiK1Ta62YuGu1JOkeVCmPtge26/ugbjF23jidnrrS7JbfLbMkW/1rBaRb64ty0ju8YyZ/U+Hvxolb1+seXlX8h2MfViyvPB3S2IKh/CkA9SWLQ5sxSr8xwNd6UKqVgmiOdubsKIznX4aMVuPk7ZbXVJbpGbd/GjV4DAAAcju9bjoe71+GrNfkbPXM2pbHtc7JTfkvrz94SXDWbiX5IoFxrIoEnLeeiT1WSd8u1rIDTclSrC6G5xtK1bmf/7Yh1Tl+3w+Ssb84wpsi1zofuuieXvPeszd91+/vbxalvMBc+7SM/9QvWrVGDuA+25r3Ndvli1lx6vLWL/Ud890arhrlQRAhzC2DsSaFk7gn/OXs8L3260uiSXFDfcAYZ3qsOYnvWZt+43nv5qg09PETXGYMyft2UKCw0K4KEeccy6tw0nzpzj3ukrffYaCA13pS4iomwwH9zdgjtb1mT8j9v41odnU1yqLXOhoR2uon/Lmkxaup3r31hMyg7fnEFU8A+uyxk7QJPqlfjPrU1ZtSuLm8f9xEkfXI9Hw12pPyEiPHFjPE2qV+Shj1ezON03T7blH70W//0iwjM3NWbK3S04k5NH3/HLGPfDVs8V6CEFM38uM9sBuL5JVSYMSmLTb8cYM2st53Lz3FydZ2m4K3UJIYEBvN0/gZiKoQyeksK6vUetLumyFTXPvTg61oti/qgOXN+4Ki98s9HnblmY5zxn4ChJugPd4mP4W/c4vly9jz5vL+XXfcfcWZ5HabgrVQzVw8OYObQVlcsGM3x6KkdP5Vhd0mUpWF+lJMqGBPJS36Y0rFaBkR+l+dRa+AXhXtKxA9zbqQ5v90/gt6Nn6PvOT2zJ8I0F11wKdxGpJCKfishGEdkgIq1FJEJEFohIunMb7q5ilbJS5XIhvOX8Sz764zSfmkFzOScVixIaFMC4/okADJ+e6jMnWX9vy5R87OJccO3L+9sRGhTA8GmpPtGDd/XI/XXgG2NMfaApsAEYAyw0xsQCC53PlbKFhJrh/N/18SzcmMHt7y7zmaO4/BOqrn2PmpXDePX2Zqzbe4ynvvSNC7zynG3ykrZlCqtasQxv3NGcrZknGDY11evnwZf4P7eIVAA6ABMBjDHZxpgsoDcwxfm2KUAf10pUyrsMan0lL/dtSnrGCW4Yu9gnevB/dgn+5ejSIIb7OtdlxvLdfLzC+y/w+r0t457v17ZuJM/e1Jhfth/ifi9fqsGV3+VXAZnA+yKySkTeE5GyQIwxZj+Acxtd1BeLyFARSRGRlMxM35yBoPyTiHBLYnXmj+xARFgw90xL9fqLXfKMcaktU9iobvVoVzeSv89aw5Nz1nv1LJJcF0+oFqVfi5r8q3cjFqcf5OFPVpN9zjvH70q4BwIJwDhjTHPgJJfRgjHGvGuMSTLGJEVFRblQhlLWiK4QytsDEjl44iw3jl3KPi9eNtaVE6oXCnAI7w5KJLl1LSb/tIOX5m92y/f1hDw39NyL0u/qGjxwTV1mrdrLw5+u9spzEK6E+x5gjzHmF+fzT8kP+wMiUhXAuc1wrUSlvFezGpX4/N62nM4+x/VevGxs4RtWuENYcCBP9mpI/5Y1eefHrby6YLNXHsGW9CKmSxERRnePY3S3esxO28fIj9K8LuBLHO7GmN+A3SIS59zVBfgVmAMkO/clA7NdqlApL9egagW+KLRs7DfrvC/gL7xhhbs8fmM8fZpV4/WF6fR6c4nX3fTjfFvGA2MHeKBLLI9d14Bv1v/GkA9SyPGiFpWrs2XuB6aLyBqgGfAs8DzQTUTSgW7O50rZWqxz2djYmHLcMy2V5+d511o0F7thhatCAgN4rV9zJiYnsfPQKQZNXM6G/d5zoY+n2jKFDelwFc/clN+Dv3HsEtbu8Y4T7C6FuzEmzdk3b2KM6WOMOWKMOWSM6WKMiXVufXNRCqUuU3jZYL4Y0ZY7WtTgnR+38tSX671mVcU8Y9x6UvFCXRrE8PaABA6eOEuft5ayfp93BNz5K1Q9GO4A/VteybsDEzlyKpveby3hubkbLF9wTK9QVcqNggIc/Kt3Iwa2upL3l+7gw+W7rC4JyJ/v7emA6xwXzdwH2xMeFszwaSs5etr6q3gLpiq6u+delO4NqzB/VMfzN3vp+foiS3/Jabgr5WZBAQ6e6tWQTnFRPDXnV9bsybK6pGLdsMIdosuH8lb/BPZlneaeqalkHLO2B19wQtWT/2oprOBmLx8OaUn2uTwGT05h1a4jpfLZF9JwV8oDHA7h1duaEVU+hOHTVrLj4ElL67mc9dxdlXhlOM/f0oSVu47Q/bVFbLdw7HkePqF6MW3qRDIx+WocAjeP+4kvV+8r3QLQcFfKY8LLBjNuQALHzuTQ47VFTFi0zZIefMENK0or3AFuTazO1w+0B2D4tFSOnbGmRXO+LVOKYy8QX60C80d3JOnKcEbNTOPl+ZtK9YpWDXelPKhJ9Ur8d3RHOtSL4pm5G5j2S+n34Euz71xY3ehyvHZ7M9IzTtDtlR9J3Vn6cytcXfLXVeVCAnlv0NX0bnYFY7/bwhsL00vtszXclfKwmAqhjB+QSOe4KP715XrSdmeV6uef7ztbkG+d4qKZNbwNIYEBDJuayoFS7sGfXzjMgiP3AhXDgnipbxNuSajOG9+l897ibaVyBK/hrlQpcDiEV29vRnT5UO6dlsrhk6W3oqDVR69Na1RiYnISp7JzGTF9ZaleyVpwEVNpnEz+MyLCv/s0onNcNP/+egOjZnp+yWgNd6VKSaWwYN4ZkMjBE9k8+NGqUpsHbWXfuUBsTHmeu7kxKTuP0OetpaW2kmZpzXMvjjLBAUxMTmJU13rMWb2PYdNSPXoEr+GuVClqXL0iT/dpyOL0g/R4bVGprAfvLQHXu9kVjB+YSOaJs/R+aynPzdvA2XOe/QVXGleoXg4R4YEudRlzbX0W/HqAYVNTPPYz0HBXqpTdfnVNZgxpxcmz5xg2NYUTHr6rjztvWOGqHg2r8N9RHbk1oTrjf9zGI5+u8WibxlMLh7lCRBjW4Sr+7/oG/HdDBv/+aoNHPkfDXSkLtK5TmbF3NGf7wZPcPn4Zh06c9dhnWTXX+2IqhgXxwq1NeKh7/oqKvd5c4rETrQVtDy85cD9PRPhr+6t4sEssLWpHeOQzNNyVskibupGMG5BIesYJ7pq8gi0Zxz3yOb+fVPSuhLvvmljeG5TErsOnSJ7kmQXH3HGDbE8a1a0eNzat5pHvreGulIV6NKzC2Duas+vwKXq9uZTNB9wf8N7Wdy6sa3wMb/f/fcExd59ozfPSX2ylQcNdKYv1aFiFuQ+0Jyw4kHumpbq9B//7PHfvDLhOcdHMe7ADlcvm37LQnTee/r0t451j9yQNd6W8QLVKZRh7R3N2HDzJ3z9d49ZlCrxlrvefiSofwlv9Ezhw7Az3THPfgmN65K6UslzrOpV5pGd9vl67n0lLd7jt+3pzW6aw5jXDeeGWJqzalUX31xaxLdP1aaIFM4W8tefuSRruSnmRYR2uont8DM/N3cCKHe5Zi8Vb5rkXx80J+QuOCTB82kpOZbvWoir4V4sPDN3tNNyV8iIiwku3NaV6eBlGTF/plhk0Vi0cVlJ1o8vxxh3N2ZxxnEdnrXWpRZXnY2N3Jw13pbxMhdAgxg1IJDs3j+teX8LYhekuXehj9doyJdE+NorRXevxRdo+np27gTM5JbuK0xsvYiotGu5KeaEGVSuwYFRHujeM4eUFm+n15hJ2Hz5Vou9l5aqQrhjRuS79rq7BhMXbuf6NxaSUoE2V62UXcJUmDXelvFRU+RDevDOBCYOS2Jt1mrsnryjRXY28YeGwknA4hOdvacLku67mTE4efccv44nZ6y5rqqjxofMN7qbhrpSX6xYfw7j+iWQcP8tf3l9+2bfs8/W53p3iovl2VAeSW9fig593cuu4n4p9ojXXR2YKeYKGu1I+oF1sJBOTkzh8Mpvbxi8j83jx16IxNug7lwsJ5MleDZmYnMSmA8d57PN1xTrR6msnk91Jw10pH5FUK4KZQ1tz7EwOw6elknG8eBf6+MJFTMV1Tf0YRnetx+er9hbrloUF+e9LJ5PdxQb/uZXyH/HVKvDirU1Zs/coXV/+kY9Tdl/yCNbX2zIXGtG5brFvWagnVJVSPuPGptWY92B74qqU55FP1zBw4nJ2Hbr4TBrj5SsjXq6CWxbGVAgledJyPkvdc9FfcL56MtkdNNyV8kF1osoxc2hrnu7TiFW7jtDjtUV8eJE2hR37zpXCgpk6uCV1o8vxt09Wk/z+iiIXHDM+OMffXTTclfJRDocwsNWVLBjdkaRa4Tz6+Vqm/rzzf95XMM/dbgevtSPL8smw1jzVqyE/bz3E0KmpHLzgpic6W0Yp5bOqVSrDhEFJtKsbyT+/WMdnqXv+8Lq337DCFQ6HkNymFi/c2pi03Vn8dUrKH67mzS2YKWTDsV+KhrtSNhAaFMDku66m1VURPPbFWr5Z99v51+zYlrnQTc2r89rtzUjbncWoj9POz4P/vS1jZXXWcGnIIrJDRNaKSJqIpDj3RYjIAhFJd27D3VOqUurPBAY4GHtHAldFluOeaam8Mn8T8PuRu11my1zMdY2r8nCPOOau3c+omWmczs7VtoyLOhtjmhljkpzPxwALjTGxwELnc6VUKYgqH8Ls+9pyS0J13vhuC/PW7verG1aM6FyXx65rwLfrDzB0agpncvJbNP4w9gsFeuB79gY6OR9PAX4A/u6Bz1FKFSEowMEzNzUiPeM4w6evpHnNSoD/zPX+a/urCAsO5NHP17I4/SBgv5PJxeHqkbsB5otIqogMde6LMcbsB3Buo138DKXUZQoNCuCjoa24u23t8xf6+FNr4s6WNXnt9mbnn/vjCVVXj9zbGmP2iUg0sEBENhb3C52/DIYC1KxZ08UylFIXCgsO5PEb47mhaVXmrz9AXJXyVpdUqvo0v4Kw4AB2HjpFoB3WXrhM4q4b8YrIk8AJYAjQyRizX0SqAj8YY+L+7GuTkpJMSkqKW+pQSil/ISKphc53/kGJf52JSFkRKV/wGOgOrAPmAMnOtyUDs0v6GUoppUrGlbZMDPC5c3pVIPChMeYbEVkBfCwig4FdQF/Xy1RKKXU5ShzuxphtQNMi9h8CurhSlFJKKdf431kGpZTyAxruSillQxruSillQxruSillQxruSillQ267iMmlIkQygf+9y0DxRQIH3VSOr9Ax+wcds38o6ZivNMZEFfWCV4S7q0Qk5WJXadmVjtk/6Jj9gyfGrG0ZpZSyIQ13pZSyIbuE+7tWF2ABHbN/0DH7B7eP2RY9d6WUUn9klyN3pZRShWi4K6WUDfl0uItITxHZJCJbRMQ2N+IWkUkikiEi6wrtixCRBSKS7tyGF3rtH86fwSYR6WFN1a4RkRoi8r2IbBCR9SLyoHO/bcctIqEislxEVjvH/JRzv23HDCAiASKySkS+cj639XgBRGSHiKwVkTQRSXHu8+y4jTE++QcIALYCVwHBwGog3uq63DS2DkACsK7Qvv8AY5yPxwAvOB/HO8ceAtR2/kwCrB5DCcZcFUhwPi4PbHaOzbbjBgQo53wcBPwCtLLzmJ3jGA18CHzlfG7r8TrHsgOIvGCfR8fty0fuLYAtxphtxphs4COgt8U1uYUxZhFw+ILdvYEpzsdTgD6F9n9kjDlrjNkObCH/Z+NTjDH7jTErnY+PAxuAK7DxuE2+E86nQc4/BhuPWUSqA9cD7xXabdvxXoJHx+3L4X4FsLvQ8z3OfXYVY4zZD/lBCEQ799vu5yAitYDm5B/J2nrczhZFGpABLDDG2H3MrwGPAHmF9tl5vAUMMF9EUkVkqHOfR8ftym32rCZF7PPHeZ22+jmISDngM2CkMeaY8zaORb61iH0+N25jTC7QTEQqkX/bykZ/8nafHrOI3ABkGGNSRaRTcb6kiH0+M94LtDXG7BORaGCBiGz8k/e6Zdy+fOS+B6hR6Hl1YJ9FtZSGAyJSFcC5zXDut83PQUSCyA/26caYWc7dth83gDEmC/gB6Il9x9wW6CUiO8hvo14jItOw73jPM8bsc24zgM/Jb7N4dNy+HO4rgFgRqS0iwUA/YI7FNXnSHCDZ+TgZmF1ofz8RCRGR2kAssNyC+lwi+YfoE4ENxphXCr1k23GLSJTziB0RKQN0BTZi0zEbY/5hjKlujKlF/t/X74wxA7DpeAuISFkRKV/wGOgOrMPT47b6LLKLZ6CvI39WxVbgMavrceO4ZgD7gRzyf4sPBioDC4F05zai0Psfc/4MNgHXWl1/Ccfcjvx/eq4B0px/rrPzuIEmwCrnmNcBjzv323bMhcbRid9ny9h6vOTP6Fvt/LO+IKs8PW5dfkAppWzIl9sySimlLkLDXSmlbEjDXSmlbEjDXSmlbEjDXSmlbEjDXSmlbEjDXSmlbOj/AbPwjBgQxrdqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# placeholder to track the SOH over time\n",
    "vals = np.zeros((steps))\n",
    "\n",
    "# simulation\n",
    "for i in range(0, steps):\n",
    "    if(soh >= 50):\n",
    "        idx = np.random.randint(1, 3)\n",
    "    else:\n",
    "        idx = np.random.randint(0, 3)\n",
    "    vals[i] = soh\n",
    "    soh = update_soh(soh, actions[idx])\n",
    "    state = get_state(soh)\n",
    "plt.plot(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R(healthy + maintenance): -1.0\n",
      "R(healthy + short-mission): 1.0\n",
      "R(healthy + long-mission): 5.0\n",
      "R(good + maintenance): 0.0\n",
      "R(good + short-mission): 5.0\n",
      "R(good + long-mission): 1.0\n",
      "R(degraded + maintenance): 5.0\n",
      "R(degraded + short-mission): -1.0\n",
      "R(degraded + long-mission): -5.0\n",
      "R(dead + maintenance): 0.0\n",
      "R(dead + short-mission): -99.0\n",
      "R(dead + long-mission): -99.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -1.,   1.,   5.],\n",
       "       [  0.,   5.,   1.],\n",
       "       [  5.,  -1.,  -5.],\n",
       "       [  0., -99., -99.]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = build_R(states, actions, rewards, verbose=True)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(healthy | healthy , maintenance): 1.0\n",
      "P(good | healthy , maintenance): 0.0\n",
      "P(degraded | healthy , maintenance): 0.0\n",
      "P(dead | healthy , maintenance): 0.0\n",
      "P(healthy | healthy , short-mission): 0.99\n",
      "P(good | healthy , short-mission): 0.01\n",
      "P(degraded | healthy , short-mission): 0.0\n",
      "P(dead | healthy , short-mission): 0.0\n",
      "P(healthy | healthy , long-mission): 0.9\n",
      "P(good | healthy , long-mission): 0.09\n",
      "P(degraded | healthy , long-mission): 0.01\n",
      "P(dead | healthy , long-mission): 0.0\n",
      "P(healthy | good , maintenance): 0.9\n",
      "P(good | good , maintenance): 0.1\n",
      "P(degraded | good , maintenance): 0.0\n",
      "P(dead | good , maintenance): 0.0\n",
      "P(healthy | good , short-mission): 0.0\n",
      "P(good | good , short-mission): 0.9\n",
      "P(degraded | good , short-mission): 0.1\n",
      "P(dead | good , short-mission): 0.0\n",
      "P(healthy | good , long-mission): 0.0\n",
      "P(good | good , long-mission): 0.8\n",
      "P(degraded | good , long-mission): 0.2\n",
      "P(dead | good , long-mission): 0.0\n",
      "P(healthy | degraded , maintenance): 0.05\n",
      "P(good | degraded , maintenance): 0.75\n",
      "P(degraded | degraded , maintenance): 0.2\n",
      "P(dead | degraded , maintenance): 0.0\n",
      "P(healthy | degraded , short-mission): 0.0\n",
      "P(good | degraded , short-mission): 0.0\n",
      "P(degraded | degraded , short-mission): 0.7\n",
      "P(dead | degraded , short-mission): 0.3\n",
      "P(healthy | degraded , long-mission): 0.0\n",
      "P(good | degraded , long-mission): 0.0\n",
      "P(degraded | degraded , long-mission): 0.05\n",
      "P(dead | degraded , long-mission): 0.95\n",
      "P(healthy | dead , maintenance): 0.0\n",
      "P(good | dead , maintenance): 0.15\n",
      "P(degraded | dead , maintenance): 0.65\n",
      "P(dead | dead , maintenance): 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1.  , 0.  , 0.  , 0.  ],\n",
       "        [0.99, 0.01, 0.  , 0.  ],\n",
       "        [0.9 , 0.09, 0.01, 0.  ]],\n",
       "\n",
       "       [[0.9 , 0.1 , 0.  , 0.  ],\n",
       "        [0.  , 0.9 , 0.1 , 0.  ],\n",
       "        [0.  , 0.8 , 0.2 , 0.  ]],\n",
       "\n",
       "       [[0.05, 0.75, 0.2 , 0.  ],\n",
       "        [0.  , 0.  , 0.7 , 0.3 ],\n",
       "        [0.  , 0.  , 0.05, 0.95]],\n",
       "\n",
       "       [[0.  , 0.15, 0.65, 0.2 ],\n",
       "        [0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ]]])"
      ]
     },
     "execution_count": 1625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = build_T(states, actions, verbose=True)\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed\n"
     ]
    }
   ],
   "source": [
    "if(np.all(T.sum(axis=2) == 1)):\n",
    "    print(\"passed\")\n",
    "else:\n",
    "    print(\"failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False, False]])"
      ]
     },
     "execution_count": 1629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.sum(axis=2) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.ones((3,4,3))\n",
    "x[2,2,2] = 1\n",
    "np.all(x == 1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
