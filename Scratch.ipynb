{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import Bernoulli, MultivariateNormal, Categorical\n",
    "import gym\n",
    "\n",
    "import notebook_setup\n",
    "from tqdm.auto import tqdm, trange\n",
    "from systems import CartPoleEnv\n",
    "from systems import CartPoleContinuousEnv\n",
    "from ppo import ActorCriticDiscrete, ActorCriticMultiBinary, ActorCriticBox, PPO, DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ppo_params = dict(\n",
    "    state_dim=4,\n",
    "    action_dim=2,\n",
    "    n_latent_var=32,\n",
    "    lr=0.02,\n",
    "    epochs=5,\n",
    "    update_interval=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "agent = PPO(CartPoleEnv(), ActorCriticDiscrete, **ppo_params)\n",
    "rewards = agent.learn(30000)\n",
    "plt.scatter(np.arange(len(rewards)), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ActorCriticDiscrete(state_dim=4, action_dim=2, n_latent_var=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "\n",
    "ppo_params = dict(\n",
    "    state_dim=env.observation_space.shape[0],\n",
    "    action_dim=env.action_space.shape[0],\n",
    "    n_latent_var=64,\n",
    "    lr=0.0003,\n",
    "    epochs=75,\n",
    "    update_interval=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "agent = PPO(env, ActorCriticBox, **ppo_params)\n",
    "rewards = agent.learn(3000)\n",
    "plt.scatter(np.arange(len(rewards)), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env = CartPoleContinuousEnv()\n",
    "\n",
    "ppo_params = dict(\n",
    "    state_dim=env.observation_space.shape[0],\n",
    "    action_dim=env.action_space.shape[0],\n",
    "    n_latent_var=32,\n",
    "    lr=0.02,\n",
    "    epochs=25,\n",
    "    update_interval=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "agent = PPO(env, ActorCriticBox, **ppo_params)\n",
    "rewards = agent.learn(10000)\n",
    "plt.scatter(np.arange(len(rewards)), rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Discretized Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ActorCriticBoxDiscrete(ActorCriticBox):\n",
    "    \n",
    "    def predict(self, state):\n",
    "        action, logprob = super().predict(state)\n",
    "        return int(np.round(np.clip(action.item(), 0, 1))), logprob\n",
    "\n",
    "    def evaluate(self, state, action):\n",
    "        action_logprobs, state_value, dist_entropy = \\\n",
    "            super().evaluate(state, action)\n",
    "        return action_logprobs, state_value, dist_entropy\n",
    "\n",
    "env = CartPoleEnv()\n",
    "\n",
    "ppo_params = dict(\n",
    "    state_dim=4,\n",
    "    action_dim=1,\n",
    "    n_latent_var=64,\n",
    "    lr=0.002,\n",
    "    epochs=50,\n",
    "    update_interval=500\n",
    ")\n",
    "\n",
    "agent = PPO(env, ActorCriticBoxDiscrete, **ppo_params)\n",
    "rewards = agent.learn(10000)\n",
    "plt.scatter(np.arange(len(rewards)), rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadcopter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systems.quadcopter import Quadcopter, QuadcopterSupervisorEnv, Controller, QUADPARAMS, CONTROLLER_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = QuadcopterSupervisorEnv(Controller(Quadcopter()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.150793  , 10.0325985 , -8.3591585 ,  0.5563135 ,  0.74002427,\n",
       "        0.9572367 ,  0.46991718, -0.06050808,  0.4406542 , -0.05996131,\n",
       "        0.02197874, -0.05602194], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.36089122,  8.51193277, -8.57927884])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.ctrl.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97627008, 4.30378733, 2.05526752])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.start_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1199.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = QuadcopterSupervisorEnv(Controller(Quadcopter()))\n",
    "T = 1200\n",
    "pos = np.zeros((T, 3))\n",
    "env.reset(position=(0,0,0), linear_rate=(0,0,0), orientation=(0,0,0), angular_rate=(0,0,0), target=(3,1,2))\n",
    "pos[0] = env.start_pos\n",
    "for t in trange(1, T, leave=False):\n",
    "    env.step(0.)\n",
    "    pos[t] = env.ctrl.quadcopter.state[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1199.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = QuadcopterSupervisorEnv(Controller(Quadcopter()))\n",
    "factor = 0.15\n",
    "pos_ = np.zeros((T, 3))\n",
    "env.reset(position=(0,0,0), linear_rate=(0,0,0), orientation=(0,0,0), angular_rate=(0,0,0), target=(3,1,2))\n",
    "pos_[0] = env.start_pos\n",
    "for t in trange(1, T, leave=False):\n",
    "    env.step(factor)\n",
    "    pos_[t] = env.ctrl.quadcopter.state[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8), constrained_layout=True)\n",
    "gs = fig.add_gridspec(3, 1)\n",
    "ax = fig.add_subplot(gs[0:2, 0], projection='3d')\n",
    "ax.plot(pos[:, 0], pos[:, 1], pos[:, 2], label='No supervision', color='b')\n",
    "ax.plot(pos_[:, 0], pos_[:, 1], pos_[:, 2], label=f'{factor:.2f}', color='r')\n",
    "ax.text(*env.start_pos, \"start\")\n",
    "ax.text(*env.ctrl.target, \"end\")\n",
    "ax.legend()\n",
    "\n",
    "# us = np.linspace(0, 2 * np.pi, 16)\n",
    "# ts = np.linspace(0, 1000, 16)\n",
    "# line = env.start + env.direction * t\n",
    "# us, ts = np.meshgrid(us, ts)\n",
    "\n",
    "ax = fig.add_subplot(gs[2:, 0])\n",
    "ax.plot(pos[:, 0], 'r:', label='x')\n",
    "ax.plot(pos_[:, 0], 'b:')\n",
    "ax.plot(pos[:, 1], 'r-', label='y')\n",
    "ax.plot(pos_[:, 1], 'b-')\n",
    "ax.plot(pos[:, 2], 'r--', label='z')\n",
    "ax.plot(pos_[:, 2], 'b--')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
